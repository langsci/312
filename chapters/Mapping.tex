    \documentclass[output=paper]{langscibook}
\ChapterDOI{10.5281/zenodo.10185966}
\author{Jamie Y. Findlay\affiliation{University of Oslo}  and  Roxanne Taylor\affiliation{University of Huddersfield} and  Anna Kibort\affiliation{Trinity College Library} }
\title{Argument structure and mapping theory}

\abstract{This chapter presents the LFG view of two closely related areas of inquiry: argument structure, a level of structure which represents the syntactically realisable arguments of a predicate, and mapping theory, the theory of how those arguments are linked to grammatical functions at \fstruc, as well as of alternations in this linking brought about by processes like passivisation. After introducing some preliminary concepts, the chapter explores various approaches within LFG: the earliest work using lexical rules to explain argument alternations, the ``classical'' version of Lexical Mapping Theory (LMT) developed in the late '80s and early '90s, and  various subsequent modifications, extensions, and reimaginings of LMT, including contemporary work focussing on the formal status of argument structure and mapping theory, and their connection to the rest of the grammar. }
\IfFileExists{../localcommands.tex}{
   \addbibresource{../localbibliography.bib}
   \addbibresource{thisvolume.bib}
   \input{../localpackages}
   \input{../localcommands}
   \input{../localhyphenation}
   \togglepaper[5]%%chapternumber
}{}

\forestset{
default preamble={for tree={s sep=5mm, inner sep=1, l=0pt}}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
\label{chap:Mapping}

\section{Introduction}
\label{sec:argstr:intro}

Predicates have both syntactic and semantic arguments, and the two are not
always aligned. For instance, expletives, as shown in (\ref{ex:expletives}), are
syntactic but not semantic arguments of their verbal governors:

\ea\label{ex:expletives}
\ea \emph{It} is snowing.
\ex \emph{There} seems to be a problem.
\z
\z
%
On the other hand, there are verbs like \textit{saddle}: conceptually, a
saddling event involves three entities, the saddler, the saddled (usually a
horse), and the saddle itself, but only the first two are expressible in the
syntax \citep[cf.][]{bresnan:polyadicity}. Similarly, there are clear patterns
regarding which kinds of semantic arguments are realised by which kinds of
grammatical functions -- in general, more Agent-like arguments are more likely
to be subjects than more Patient-like arguments, which are more likely to be
objects -- but there are also exceptions. There are, for example, verbs which
seem to express the same type of event but to realise the semantic participants
differently in the syntax \citep[132]{Rappaport83}:

\ea\label{ex:fear-frighten}
\ea Fred fears the prospect of failure.
\ex The prospect of failure frightens Fred.
\z
\ex\label{ex:like-please}
\ea I like a job well done.
\ex A job well done pleases me.
\z
\z
%

Due to these kinds of mismatches, neither syntactic nor semantic arguments can
be reduced to the other, and instead we need some intervening level of
representation that can mediate the relationship between them. This is what is
known as \fm{argument structure}, and in LFG is often taken to constitute a
separate module of the grammar called \astruc. Although it sits between syntax
and (lexical) semantics, \argstruc{} itself is often taken to be a specifically
syntactic level of representation \citep{Alsina2001},%
%
\footnote{Indeed, in the Minimalist tradition, \argstruc{} is often represented
  in the phrasal syntax itself -- see \citet{harley:arg-struc} and references
  therein for an overview.}
%
whose primary purpose is to explain a predicate's syntactic valency patterns --
while acknowledging that at least some of these explanations are to be found in
lexical semantic properties. The arguments represented at argument structure are
therefore those which can or must be realised syntactically.

Explaining how exactly these arguments are realised is the purview of
\textsc{mapping theory}. Such a theory seeks generalisations in the mapping
between argument structure and syntax proper, and to explain any alternations
which are possible (such as passivisation, causativisation, detransitivisation,
etc.). In LFG, this means determining what \fm{grammatical function} (GF) the
argument will instantiate -- overt phrasal realisation is then handled by the
language-specific phrase-structure rules or case-marking system which determines
how particular GFs surface (see \citetv{chapters/CoreConcepts,chapters/GFs} for more on LFG's view of grammatical functions and their
relation to phrasal syntax).

As part of this LFG handbook, the present chapter focusses on providing a survey
of work on argument structure and mapping theory which takes a
Lexical-Functional approach.%
%
\footnote{For general introductions as well as critical overviews of work in
  other traditions, the reader is directed to
  \citet[][]{Grimshaw90,comrie:argument-structure,levin-hovav05,ramchand:argument-structure,williams:arguments}.
  For a different perspective on the LFG literature, see
  \citet[ch.~9]{DLM:LFG}.}
%
The structure of the chapter is as follows: we begin, in
Section~\ref{sec:argstr:meta-questions}, with a brief high-level introduction to some
of the questions and phenomena which we will return to throughout the chapter.
Section~\ref{sec:argstr:lexical-rules} then looks at the earliest work on these
problems in LFG, which used \fm{lexical rules} to account for argument
alternations. Section~\ref{sec:argstr:classical-lmt}, the largest of the chapter,
presents the still-canonical theory of argument structure and mapping developed
in the late 1980s and early 1990s, known as \textsc{lexical mapping theory}
(LMT). Section~\ref{sec:argstr:morphosemantic-alternations} examines a different
version of LMT, that of \citeauthor{Kibort2007} (\citeyear{Kibort2007},
\textit{i.a.}) which, among other things, is designed to extend the empirical
coverage of the mapping theory to so-called morphosemantic alternations.
Section~\ref{sec:argstr:formal-issues} delves more deeply into some formal issues and
alternative proposals, before Section~\ref{sec:argstr:conclusion} concludes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background and basic concepts}
\label{sec:argstr:meta-questions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{From semantics to syntax}
\label{sec:argstr:sem-to-syn}

There are regularities in the ways that semantic participants of predicates are
realised syntactically. %
For example, in a nominative-accusative language like English, when a verb
describes an event that has a volitional Agent and a Theme or Patient affected
by the event, the Agent will be realised as the active voice subject and the
Theme\slash Patient as the object:

\ea\label{ex:simple-transitives}
\ea Your dog is chasing my rabbit!\\(cf. \#\,My rabbit is chasing your dog!%
%
\footnote{The point of these anomalous alternatives is to illustrate that the
  (prototypical) situations presented are expressed via the (a) encodings, where
  the Agent is a subject and the Theme\slash Patient an object, rather than the
  \textit{a~priori} equally plausible (b) encodings, where the pairings of
  semantic and syntactic roles are reversed. The (b) sentences are of course
  perfectly grammatical strings of English, but they describe situations which
  are at odds with our real-world know\-ledge or expectations, precisely because
  the subjects in each case are interpreted as Agents.})
%
\ex The engineers will build the bridge there.\\(cf. \#\,The bridge will build
the engineers there.)%
\ex The teacher opened the cupboard.\\(cf. \#\,The cupboard opened the teacher.)%
\z
\z
%
Similarly, if the sentence expresses an Instrument used to perform the action
described, along with the Theme\slash Patient, then the Instrument is the subject and the
Theme\slash Patient the object:

\ea
\ea The key opened the cupboard.\\(cf. \#\,The cupboard opened the key.)
\z
\z
%
But if the Agent is also included, then \emph{it} is the subject:

\ea\label{ex:transitive-with-Instrument}
The teacher opened the cupboard with the key.
\z
%
This generalisation goes back to \citet[33]{fillmore:case}, who expresses it as
follows:

\ea\label{ex:fillmore-scale}
If there is an A [=~Agent], it becomes the subject; otherwise, if there is an I [=~Instrument],
it becomes the subject; otherwise, the subject is the O [=~objective, i.e. Theme\slash Patient].
\z
%
This is a productive rule (at least in English), as can be seen from the fact
that invented words will also follow the same pattern.
\citet[5--6]{alsina1996the-role}, for instance, imagines a verb
\textit{obliquate}, meaning `build or place in an oblique position or
direction', and notes the clear intuition that, if such a verb existed, we would
say things like (\ref{ex:good-obliquate}), but not
like~(\ref{ex:bad-obliquate}):

\ea
\ea[]{Jim obliquated the door of the closet.}\label{ex:good-obliquate}
\ex[\#]{The door of the closet obliquated Jim.}\label{ex:bad-obliquate}
\z
\z


All this goes to illustrate a key explanandum: the semantic relationship which
an argument bears to its verb is also implicated in determining its syntactic
relationship, but in what way precisely? Mapping theory is interested in
discovering the nature of this connection, and in finding generalisations over
the links between semantic and syntactic relationships.

The observation in (\ref{ex:fillmore-scale}) induces a ranking of semantic\slash
thematic roles,%
%
\footnote{We will use these two terms interchangeably in this chapter, drawing
  no theoretical distinction between them.}
%
where the highest available argument becomes the subject:

\ea
A $>$ I $>$ O
\z
%
This can be seen as a precursor to the well-known \fm{thematic hierarchy}
\citep[43]{jackendoff72}, of which there have been many versions. The one which
has been most influential in LFG comes from \citet[23]{bresnan1989locative}, and
is shown in~(\ref{ex:thematic-hierarchy}):

\ea\label{ex:thematic-hierarchy}
\textit{The Thematic Hierarchy:}\\
Agent $>$ Beneficiary $>$ Recipient\slash Experiencer\\\hfill $>$ Instrument $>$
Theme/Patient $>$ Location%
\z
%
Arguments which are more thematically ``prominent'' on this hierarchy tend to be
realised by more grammatically ``prominent'' GFs, e.g. as defined by the
Keenan-Comrie hierarchy (\citealp{keenan1977noun}; see also
\citetv{chapters/GFs}) -- in particular, the \SUBJ function is usually taken by
the the argument highest on the thematic hierarchy \citep{Grimshaw90,speas1990}.
This insight is often at the core of mapping theories, and so the thematic
hierarchy figures centrally in the standard version of Lexical Mapping Theory,
which we explore in Section~\ref{sec:argstr:classical-lmt}, as well as in other
approaches discussed below.

The use of thematic hierarchies has also been challenged, however. For one
thing, a consistent list of roles and definitions has proved elusive, and
classification of arguments can therefore be problematic and open to
disagreement
\citep{gawron:phdthesis,Dowty1991,ackerman:protoroles,davis:thematicroles}. For
another, even when a set of roles is agreed on, the question of their relative
ordering has not been settled, and different hierarchies have been proposed for
different phenomena, or even for the same phenomenon
(\citealp[65ff.]{Newmeyer2002}; \citealp[ch.~6]{levin-hovav05};
\citealp{rappaport:thematic}). While it is clearly possible that different
orderings could be relevant for different things, the extent of the variability
in the literature, even with respect to one and the same phenomenon, stands in
stark contrast to the putative appeal of a unifying thematic hierarchy where a
fixed set of roles is used in order to abstract away from predicate-specific
semantic entailments. Because of these concerns, some recent work in LFG's
mapping theory, most notably that of
\citeauthor{Kibort2007}~(\citeyear{Kibort2007}, \textit{i.a.}), has attempted
to do without thematic roles altogether. We discuss Kibort's work in
Section~\ref{sec:argstr:morphosemantic-alternations}.

Some questions of mapping depend not on the semantic relationship between an
argument and its verb, but rather on lexical semantic properties of the verb
itself. For example, \textit{break} and \textit{hit} both take Agent and Patient
arguments, but \textit{break} has an intransitive alternant, where the Patient
appears as the subject, which is impossible with \textit{hit}:

\begin{exe}
\ex\label{ex:break}
\begin{xlist}
\ex[]{The teacher broke the ruler.}
\ex[]{The ruler broke.}
\end{xlist}
%
\ex\label{ex:hit}
\begin{xlist}
\ex[]{The teacher hit the ruler.}
\ex[*]{The ruler hit.}
\end{xlist}
\end{exe}

\noindent \citet{fillmore1970} observes that this contrast is not a lexical
idiosyncrasy of these two verbs, but actually applies to two large classes of
semantically-related verbs, as shown in
(\ref{ex:break-class}--\ref{ex:hit-class}):%
%
% \footnote{The relevant generalisation appears to be that the Patients of the
%   \textit{break}-type verbs change state, whereas those of the \textit{hit}-type
%   verbs need not. Some theories might assume that they in fact have different
%   thematic roles, therefore: perhaps the latter are Themes rather than Patients,
%   for instance. Exactly where one draws the line between which lexical
%   entailments should be encoded in the inventory of thematic roles and which
%   should be part of the event structure of the verb itself is an open question.}
%

%
\begin{exe}
\ex\label{ex:break-class}
\begin{xlist}
\ex[]{The teacher \{bent / folded / shattered / cracked / \dots\} the ruler.}
\ex[]{The ruler \{bent / folded / shattered / cracked / \dots\}.}
\end{xlist}
%
\ex\label{ex:hit-class}
\begin{xlist}
\ex[]{The teacher \{slapped / struck / bumped / stroked / \dots\} the ruler.}
\ex[*]{The ruler \{slapped / struck / bumped / stroked / \dots\}.}
\end{xlist}
\end{exe}
%
Once again, we can see that this is a productive generalisation if we examine
our intuitions about invented forms. For example, let us imagine a verb
\textit{jellate}, meaning `to turn to jelly'. It is clear that this verb could
appear in the same constructions as \textit{break}.

\ea
\ea The wizard jellated the box.
\ex The box jellated.
\z
\z
%
But if we invent a word like \textit{coude}, meaning `to touch with one's
elbow', it is just as clear that it will pattern with \textit{hit}:

\ea
\ea []{I couded the wall.}
\ex [*]{The wall couded.}
\z
\z
%
We do not want to simply stipulate the possibilities for each new verb, since
then we fail to capture the regularity and productivity of our intuitions.

A mapping theory ought to give an account of these patterns. To do this, it must
have access to detailed lexical semantic information, such as event structure.
For example, a hitting event does not necessarily result in a change of state in
the affected entity, whereas a breaking event does; that is, the structure of a
hitting event does not contain a result state, in \citegen{ramchand08} terms.
Now, this may be expressed in the semantic role assigned to the affected entity
-- in some theories, the difference between Patient and Theme is that the former
undergoes a change of state while the latter does not. But often such nuances
are not captured by a simple semantic role analysis -- for example, the thematic
hierarchy in (\ref{ex:thematic-hierarchy}) collapses Theme and Patient into a
single position -- and it is certainly not apparent that there are any
principled limits on what kinds of lexical semantic information can be relevant
for questions of mapping, so it is quite possible that mapping theory needs
access to a very rich representation of lexical semantics. In general, argument
structure proposals in LFG have not taken up this challenge, instead treating
this level of representation as relatively informationally impoverished (it is
often no more than a list of arguments and their associated thematic roles).
Nevertheless, there have been, and continue to be a growing number of,
exceptions, which we examine in Section~\ref{sec:argstr:position-of-astruc}.

\subsection{Argument alternations}
\label{sec:argstr:arg-alternations}

Accounting for the syntactic realisation of semantic arguments means also
addressing the fact that a single predicate may permit multiple ways of
expressing its arguments (including not expressing some of them at all) -- that
is, the existence of \fm{argument alternations}, such as that between the
transitive and the inchoative illustrated in (\ref{ex:break}), above. Perhaps
the most famous and well-studied of these is the active-passive alternation, a
typologically common pattern whereby a transitive verb alternates with an
intransitive in which the subject argument of the transitive form is either
unexpressed or expressed as a non-core, oblique grammatical function instead:

\ea\label{ex:active-passive}%
\ea\label{ex:active}%
\emph{Active:}\\
The dog chased the rabbit.%
%
\ex\label{ex:passive}%
\emph{Passive:}\\
The rabbit was chased (by the dog).
\z
\z
%
One important property of the active-passive alternation is that it does not
involve any change in lexical semantics. That is, the situations described by
(\ref{ex:active}) and (the long version of) (\ref{ex:passive}) are
truth-conditionally equivalent, and so this alternation is described as
\fm{meaning-preserving} \citep[cf.][]{SadlerSpencer1998}. This label is slightly
infelicitous, however, since once we look beyond mere truth conditions there are
of course changes to other aspects of ``meaning'', writ large: for instance, the
information-structural Topic is the dog in (\ref{ex:active}) but the rabbit in
(\ref{ex:passive}). This is not at all surprising, since language
abhors true synonymy \citep{cruse1986, Goldberg2019}, and variation of whatever
kind is inevitably operationalised for communicative purposes
\citep{clark1987contrast,eckert2018meaning} -- but it does mean that
the term ``meaning-preserving'' must be understood in a suitably narrow sense.

Such meaning-preserving alternations are known as \fm{morphosyntactic}, since
they are morphological operations which alter the syntactic alignment of
participants; this is in contradistinction to \fm{morphosemantic} alternations,
which involve changes in (truth-conditional) lexical meaning. Another example of
a morphosyntactic alternation is locative inversion, illustrated in
(\ref{ex:locative-inversion}) for Chiche\^{w}a \citep[2]{bresnan1989locative}.
In this alternation (also found in English, as indicated by the translations
below -- see \citealt{Bresnan:Architecture}), a locative phrase which normally
appears as an oblique can surface as a subject, demoting the subject of the
non-inverted form to object:%
%
\footnote{Numbers indicate noun classes: this is in part how we can tell that
  the locative is the subject in (\ref{ex:inverted}), since the verb
  now agrees with it in this respect.}
%

\ea\label{ex:locative-inversion}
\ea
\gll Chi-ts\^{i}me chi-li    ku-mu-dzi. \\
7-well        7-be 17-3-village\\
\glt `The well is in the village.'\label{ex:uninverted}\\[0.5em]
%
\ex
\gll Ku-mu-dzi     ku-li       chi-ts\^{i}me. \\
17-3-village  17-be  7-well\\
\glt `In the village is a well.'\label{ex:inverted}%
\z \z
%
Once again, this affects certain properties of a sentence's information
structure, for instance changing what is available for contrastive focus
(\citealp[35]{bresnan1989locative}, \citealp[86--87]{Bresnan:Architecture}), but
it does not alter the truth-conditional meaning.

Morphosemantic alternations, on the other hand, change the lexical meaning of a
predicate -- a change which may then have syntactic effects, though these are in
a sense only incidental, merely following as automatic consequences of the
lexical semantic changes \citep[374]{Kibort2004}. Examples include many of the
alternations listed in \citet{levin93}, such as the \textit{spray\slash load}
alternation shown in (\ref{ex:spray-load-intro}) or the dative shift alternation
shown in (\ref{ex:dative-shift}):

\ea\label{ex:spray-load-intro}%
\ea Carly loaded the wagon with barrels.\label{ex:spray-load-intro-goal-obj}%
\ex Carly loaded barrels onto the wagon.\label{ex:spray-load-intro-theme-obj}%
\z%
\ex\label{ex:dative-shift}%
\ea Julian brought Elim the message.\label{ex:dative-shift-shifted}%
\ex Julian brought the message to Elim.\label{ex:dative-shift-unshifted}%
\z%
\z
%
In (\ref{ex:spray-load-intro-goal-obj}), the Goal\slash Location \textit{the
  wagon} is realised as the object, and in this case there is a ``holistic''
interpretation \citep[50]{levin93}, whereby the Goal\slash Location is
understood to be fully affected by the action (i.e. the wagon is filled up with
barrels). This entailment is absent from the sentence in
(\ref{ex:spray-load-intro-theme-obj}), where the Theme is realised as the object
instead. Similarly, in (\ref{ex:dative-shift-shifted}), there is an entailment
that the dative-shifted Goal object is animate
% \citep[146--147]{green:semantics,oehrle:phdthesis,Cattell1984,goldberg1995constructions},
\citep[146--147]{goldberg1995constructions},
but this same constraint does not
hold of the Goal argument in the prepositional variant
(\ref{ex:dative-shift-unshifted}), as illustrated by the following contrast:

\largerpage
\ea%
\ea [\#]{Julian brought Elim's study the message.}%
\ex []{Julian brought the message to Elim's study.}%
\z%
\z

Both of these alternations involve differing syntactic realisations of the same
arguments, but unlike the morphosyntactic alternations shown above, they also
change certain properties of the truth-conditional meanings expressed by their
governing verbs. Other morphosemantic alternations, such as the causative, also
introduce \emph{new} arguments, rather than simply rearranging existing
arguments. The causative introduces a new Causer argument, which brings about
the event described by the predicate. Here is a classic example from Turkish
\citep[5]{comrie:causatives}:

\ea%
\ea%
\gll Hasan \"ol-d\"u.\\
Hasan die-\PST\\
\glt `Hasan died.'%
\ex%
\gll Ali Hasan-\i{} \"ol-d\"ur-d\"u.\\
Ali Hasan-\OBJ{} die-\CAUS-\PST\\
\glt `Ali killed Hasan.' (lit. `Ali made Hasan die.')%
\z%
\z
%
As can be seen, this also has syntactic effects, since causativisation increases
the valency of the predicate. Here an intransitive becomes a transitive, and the
previous subject is demoted to object.

The world's languages are replete with a wide and varied selection of argument
alternations, both meaning-preserving as well as meaning-altering, many of which are
highly productive. Any mapping theory must therefore be capable of giving an
account of such alternations in general, and this has been a major focus of
research, as we will see below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lexical rules}\label{sec:argstr:lexical-rules}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Argument alternations have been at the heart of work in LFG since the very
beginning. The seeds of LFG as a framework can be found in
\citegen{bresnan1978a-realistic} work on the psychological plausibility of
transformational grammars, illustrating how the passive can be profitably viewed
as an operation on lexical representations, rather than on phrase-level
syntactic structures. \citet{bresnan:polyadicity} presents this analysis in a
more recognisably LFG-like form, and extends the approach to the formation of
intransitives and middles in English. In this and much other early work in LFG,
argument alternations are treated as involving \fm{lexical rules}, which
systematically relate the different alternants of the same verb (e.g. active and
passive). In this section, we give a brief overview of this approach, and
highlight some of the reasons why it has fallen out of favour in recent work.

In \citet{bresnan:polyadicity}, lexical items are assumed to possess abstract
predicate-argument structures, which characterise ``those arguments of a
semantic predicate that are open to grammatical interpretation''
\citep[100]{bresnan:polyadicity}. Such argument positions are then associated
with grammatical functions by various (undiscussed) lexical processes, with the
result being a \fm{lexical form} -- recognisable as what would become in LFG the
\fm{semantic form} value of a \PRED attribute \parencitetv{chapters/CoreConcepts}. For
example, the lexical form for transitive \textit{read}, as in \textit{John read
  my letter}, is given in (\ref{ex:read-lexical-form})
\citep[116]{bresnan:polyadicity}:

\ea\label{ex:read-lexical-form}
\begin{tabular}[t]{lrccl}
  \textit{read} & $\langle$ & (\SUBJ) & (\OBJ) & $\rangle$
\end{tabular}
\z
%
Here the first argument, corresponding to the reader, is linked to \SUBJ, and
the second argument, the thing read, is linked to \OBJ. The exact nature of this
initial linking of arguments to GFs is not spelled out explicitly, and is
generally taken to follow from some intrinsic pairings of  roles and syntactic
functions. What is more, in this early work, the specific role of each argument
is not labelled in the representation, and must be inferred from the combination
of their ordering and lexical idiosyncrasies of meaning. In other work
\citep[e.g.][]{baker83}, lexical forms are shown with semantic roles alongside
their associated GFs, thus highlighting both sides of the linking question
explicitly in the representation. For the sake of clarity, we will follow this
convention for the rest of this section; thus instead of
(\ref{ex:read-lexical-form}), we will write (\ref{ex:read-full-lexical-form})
for the lexical form of \textit{read}:

\ea\label{ex:read-full-lexical-form}
\begin{tabular}[t]{lrccl}
  \textit{read} & $\langle$  & Agent  & Theme   & $\rangle$\\
       &             & (\SUBJ)  & (\OBJ)    &
\end{tabular}
\z

However such structures are represented, once the links between arguments and
GFs are in place, other rules can then apply to manipulate them, capturing the
effect of various argument alternations. For example, intransitivisation is
achieved by the following lexical rule \citep[116]{bresnan:polyadicity}:

\ea\label{ex:intransitivisation-rule}
\textit{Intransitivisation:}\\
$ (\OBJ) \mapsto \varnothing$
\z
%
Here the argument previously linked to \OBJ is instead assigned the special null
GF $\varnothing$, which indicates that the argument is existentially bound in
the semantics, and is not expressed overtly in the syntax. The application of
(\ref{ex:intransitivisation-rule}) to (\ref{ex:read-full-lexical-form}) results
in the lexical form in (\ref{ex:intransitive-read-lexical-form}), corresponding
to the intransitive form of \textit{read}, as in \textit{John read all night}.

% \ea\label{ex:intransitive-read-lexical-form}
% read $((\SUBJ), \varnothing)$
% \z

\ea\label{ex:intransitive-read-lexical-form}
\begin{tabular}[t]{rcccc}
  \textit{read} & $\langle$  & Agent  & Theme   & $\rangle$\\
      &             & (\SUBJ)  & $\varnothing$   &
\end{tabular}
\z

It is clear to see how this approach can be extended to other, more complex
alternations. \citet{bresnan1982the-passive}, for instance, proposes the
following lexical rule for passivisation:%
%
\footnote{\citet{bresnan1982the-passive} is in fact the \textit{locus classicus}
  of the lexicalist approach to the passive in general. In the paper, Bresnan
  makes a compelling case against the prevailing wisdom that passivisation
  should be treated as a transformation, i.e. something that takes places in the
  phrasal syntax. Instead, she shows that it must be treated as a process
  occurring inside the lexicon. \citet[ch.~3]{BresnanEtAl2016} provide a
  contemporary presentation of the relevant arguments.}
%

\begin{exe}
\ex \label{universalpassiverule}
\textit{Passivisation:}\\
$(\SUBJ) \mapsto \varnothing / (\OBLROLE{agent})$\\
$(\OBJ) \mapsto (\SUBJ)$
\end{exe}
%
This demotes the subject to either the unexpressed null GF (as in the English
short, Agent-less passive), or an oblique (as in the English long,
\textit{by}-passive), and promotes the object to subject.


One important strength of such lexical rules is that they manipulate grammatical
functions, rather than surface constituent structures; that is,
(\ref{universalpassiverule}) promotes the \OBJ, rather than, say, moving the
post-verbal NP to the specifier position of IP. This means that the same rule
can be used across the languages of the world, with language-specific variations
falling out from the rules for c- to \fstruc{} mapping in those languages
\parencitetv{chapters/CoreConcepts}.%
%
\footnote{This insight originates from work in Relational Grammar
  \citep[e.g.][]{perlmutter1977toward}.}
%
Such an approach is a corollary of the claim that argument alternations operate
at the level of argument structure, and not directly on the phrasal syntax.

Lexical rules in LFG are taken to be \fm{redundancy rules}
\citep[638]{Bresnan:Monotonicity}: they are not applied on-line in the process of
parsing, but instead describe regular relations between items in the lexicon. In
other words, the existence of a lexical form like (\ref{ex:active-read}) implies
the existence of a corresponding passive form like (\ref{ex:passive-read}),
because of the existence of rule (\ref{universalpassiverule}):%
%
\footnote{\citet{bresnan:polyadicity,bresnan1982the-passive} presents such rules
  as directional, so that the active maps to the passive, but they can also be
  seen as bidirectional, so that the existence of either kind of entry implies
  the other -- this is how it is presented in \citet{Bresnan:Monotonicity}, for example.}
%

\ea
\ea\label{ex:active-read}
\begin{tabular}[t]{rcccc}
  \textit{read} & $\langle$  & Agent  & Theme   & $\rangle$\\
      &             & (\SUBJ)  & (\OBJ)    &
\end{tabular}
\ex\label{ex:passive-read}
\begin{tabular}[t]{rcccc}
  \textit{read} & $\langle$  & Agent  & Theme   & $\rangle$\\
      &             & (\OBLROLE{agent})  & (\SUBJ)   &
\end{tabular}
\z%
\z
%
Such a restriction follows from \citegen[118]{bresnan:polyadicity} claim that
``structures which are analyzed by lexical rules must be lexical structures, and
cannot be syntactically derived''. \citet[6]{bresnan1982the-passive} goes
further, and proposes that alterations of argument-to-GF assignments can
\emph{only} take place in the lexicon, via lexical rules, and cannot be effected
on-line by syntactic rules -- she refers to this as the principle of \fm{direct
  syntactic encoding}. Although contemporary LFG makes much less (or no) use of
lexical rules, it continues to maintain the first part of this principle, and
treats all argument alternations as applying in the lexicon, not in the syntax.

While lexical forms, which appear at \fstruc{} as the value of \PRED attributes,
are obtained by augmenting a predicate-argument structure with linkings to GFs,
at this stage in the development of LFG the formal status of the
predicate-argument structures themselves is not made explicit. They are
certainly not a separate level of representation, akin to c- and \fstruc{} (i.e.
there is no \astruc). Indeed, it is not until \citet{butt1997architecture} that
the formal position of argument structure in the LFG architecture is tackled
head on -- we will have more to say about this in
Section~\ref{sec:argstr:position-of-astruc}.

% the GF linking Formally speaking, therefore, argument structure is a
% part of \fstruc, and not a separate projection (i.e. there is no \astruc). This
% may be a saving in terms of ontological commitments, but it is not in keeping
% with the later LFG drive towards a strong kind of modularity, such that all
% levels of representation have ``their own primitives and organizing principles,
% and therefore their own internal structure and formal representation''
% \citep[265]{DLM:LFG}.

A more urgent shortcoming of the early lexical rule approach is that there is no
account of how the original assignment of GFs to arguments is accomplished --
that is, as \citet[96]{falk2001lexical} observes, early LFG has a theory of
\emph{re}mapping, via lexical rules, but no theory of the initial mapping.
\citet[112]{bresnan:polyadicity} briefly suggests some principles for default
assignments, but this is not developed more fully. Since, as we observed in
Section~\ref{sec:argstr:sem-to-syn}, the initial mapping is also amenable to systematic
study, and exhibits a number of clear generalisations, this lacuna is therefore
a significant one.

There is also the question of appropriately constraining lexical rules. Clearly
the rule of intransitivisation given in (\ref{ex:intransitivisation-rule})
cannot apply freely to any verb with an object, otherwise we would expect
examples like (\ref{ex:bad-obj-deletion}) to be grammatical, contrary to fact:

\ea
\ea[]{Naomi told the story to Jim.}%
\ex[*]{Naomi told to Jim.}\label{ex:bad-obj-deletion}%
\z%
\z
%
Lexical rules must be assigned syntactic, semantic, and morphological conditions
in order to constrain their application. Even then, it remains a fact that
lexical rules are very powerful formal devices: there are no in-principle
constraints on what kinds of alternations can be described, which means that any
remapping can be represented, including some which are most unnatural in the
world's languages \citep[639ff.]{bresnan:polyadicity}.%
%
\footnote{Of course, we may not expect formalism to constrain theory in this way
  \citep[cf.][]{poll:97:nature}, and in that case this objection is of less
  concern.}
%
% It is implied in certain works that the application of rules can be blocked by
% lexical semantic facts, but this is not worked out in any detail.

The unconstrained expressive power of lexical rules arises from the fact that
they are not \fm{monotonic} \citep{Bresnan:Monotonicity}: since such rules
\emph{overwrite} the original assignments of GFs to arguments, they are are not
information-preserving.%
%
\footnote{Note that this is not an inherent property of lexical rules
  \textit{per se}; as a reviewer notes, in XLE (the computational implementation
  of LFG -- \citealp{kaplannewman97,xledoc}), lexical rules are implemented as
  disjunctions of functional descriptions, thereby restoring monotonicity. This
  approach has also been taken in some theoretical work in LFG, starting with
  \citet{butt1997architecture} -- see Section~\ref{sec:argstr:nature-of-mapping} below.
  HPSG takes a different approach to lexical rules again, treating them as
  unary-branching rules in the type hierarchy \citep[see
  e.g.][155ff.]{dav:koe:20}.\label{fn:monotonicity}}
%
Aside from the possibility of expressing unnatural alternations, another reason
why non-monotonicity may be problematic has to do with processing. Arbitrary
re-write rules render a system intractable
\citep[cf.][]{peters:generative-power}, and this is at odds with the LFG
desideratum of psychological plausibility \citep[173--174]{kaplanbresnan82}.
However, this objection only carries weight insofar as the rules are applied
during on-line processing; if they only apply in the lexicon, their
computational power is irrelevant, since lexical entries are stored in memory.
The discovery that complex predicates necessitate an analysis whereby argument
structures can be assembled in the syntax
(\citealp{Butt1995,alsina1996the-role}; Section~\ref{sec:argstr:complex-preds} below)
challenges this solution, however. Another way to neutralise the processing
objection is by formally implementing lexical rules in such a way as to make
them tractable, such as by treating two lexical entries related by lexical rule
as a single lexical entry containing disjunctive specifications (cf.~fn.~\ref{fn:monotonicity}). This might result in quite a gap between theoretical
LFG and computational implementations (which again runs counter to the
Competence Hypothesis of \citealt{kaplanbresnan82}), but it does at least avoid
intractability.

Although none of these objections may be insurmountable, lexical rules have
nevertheless fallen out of favour in LFG. Lexical Mapping Theory has offered a
fruitful alternative that avoids the formal and conceptual issues of lexical
rules, and also goes further, by providing an account of the initial linking of
arguments and GFs. Lexical rules have not entirely disappeared, however, and are
still sometimes invoked to capture certain generalisations over the lexicon --
see e.g. \citegen[315--319]{BresnanEtAl2016} analysis of possessors and
gerundives. However, such generalisations can also be captured by using
\fm{templates} (\citealp{dalrymple2004linguistic,asudeh2013constructions},
\citetv{chapters/CoreConcepts}), providing the possibility of doing away with
lexical rules altogether.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classical LMT}
\label{sec:argstr:classical-lmt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Lexical Mapping Theory (LMT) arose in part as a result of dissatisfaction with
the shortcomings and unconstrained nature of lexical rules
\citep{Bresnan:Monotonicity}. LMT therefore attempts to offer a more principled
and constrained theory of both argument alternations and initial argument-GF
mappings. Since the foundational work in LMT
\citep{Levin1986,bresnan1989locative,bresnanzaenen90}, the theory has undergone
many alterations and extensions; some of these build on one other, some offer
competing perspectives, and some are simply different ways of saying the same
thing. In addition, some are mere extensions or minor tweaks, while others
involve rebuilding the theory from the ground up. We feel it would be both
convoluted and unilluminating to trace every divergent strand of research in the
LMT tradition, and so in this section we try to present a single coherent
version of the theory, which we call \fm{Classical LMT}. In order to maintain
this coherence, we will adapt and update analyses where necessary, provided this
does not detract from the main goals of the work in question.

Classical LMT represents what many take to be the ``canonical'' version of
mapping theory in LFG, and is the variety which often appears in textbook
presentations of the framework (as in e.g. \citealt[202ff.]{dalrymple01},
\citealt[ch.~4]{falk2001lexical}, \citealt[ch.~14]{bresnan2001lexical},
\citealt[ch.~14]{BresnanEtAl2016}, and \citealt[ch.~8]{BoNoSa19}; see also
\citealt[pp.~117ff.]{Butt2006}). However, it has long since been recognised that
the name ``\emph{Lexical} Mapping Theory'' is inappropriate, since ``the theory
cannot apply exclusively to individual words'' \citep[212]{dalrymple01}: for
example, complex predicates which are formed analytically nonetheless contribute
a single (complex) argument structure, despite the fact they contain multiple
lexemes (\citealp{MohananT1994,Butt1995,alsina1996the-role};
Section~\ref{sec:argstr:complex-preds} below). For this reason, alternative names have
been proposed for the theory, including \fm{Mapping Theory} \textit{tout court}
(as in e.g. \citealt{KM15}), \fm{Functional Mapping Theory}
\citep{alsina1996the-role}, and \fm{Linking Theory}
\citep{butt1997architecture}. We use ``Classical LMT'' as a cover term, and for
consistency with the large body of literature that uses the moniker ``LMT'', but
we do not thereby intend to deny the importance of the work on complex
predicates which shows that LMT cannot apply exclusively in the lexicon.

Our presentation of Classical LMT in this section has two parts: in
Section~\ref{sec:argstr:lmt-formalism}, we present the basic formal tools and
theoretical assumptions which characterise Classical LMT, while in
Section~\ref{sec:argstr:lmt-case-studies} we discuss several case studies which
illustrate the application of the theory to some empirical challenges, some of
which necessitate (minor) changes to the theory.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The framework}
\label{sec:argstr:lmt-formalism}

In this section, we present the theoretical and formal tools which are used in
Classical LMT. We begin in Section~\ref{sec:argstr:feature-decomposition} by
introducing the idea of decomposing grammatical functions by means of binary
features, which underpins the LMT approach to mapping. In
Section~\ref{sec:argstr:lmt-initial}, we address the question of the initial (unmarked)
mapping of arguments to GFs, something that was ignored in the lexical rule
approach. Lastly, Section~\ref{sec:argstr:arg-alternations-in-lmt} discusses the
Classical LMT approach to argument alternations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Feature decomposition}\label{sec:argstr:feature-decomposition}

In the theoretical world described above in Section~\ref{sec:argstr:lexical-rules},
arguments are associated with GFs in the lexicon. If those arguments are
realised by different GFs as the result of some alternation, like the passive,
the original assignments have to be overwritten. As discussed, this means that
argument alternations involve non-monotonic re-writing rules. The key innovation
of Classical LMT allowing it to avoid this unhappy conclusion is to underspecify
the mappings between arguments and GFs, by grouping GFs into natural classes.
Each argument can then be associated with one of these natural classes, rather
than a specific GF, thereby constraining but not totally determining its
ultimate realisation. And since the groupings of GFs are supposed to be natural,
this also answers the complaint of unconstrainedness levelled at the lexical
rule approach: no longer can we replace a GF with any other; instead, the choice
of GFs available to an argument is limited to a natural class.

\largerpage[-1]
To achieve this cross-classification, Classical LMT decomposes the GFs using two
binary-valued features, $[\pm r]$ and $[\pm o]$
\citep[24--25]{bresnan1989locative}. The first, $[\pm r]$, refers to whether a
GF is thematically restricted or not: \OBJTHETA and \OBLTHETA are; \SUBJ and
\OBJ are not. The second, $[\pm o]$, refers to whether a GF is objective or not:
\OBJ and \OBJTHETA are; \SUBJ and \OBLTHETA are not. This is illustrated in
Table~\ref{tab:feature-decomposition}.
%
\begin{table}[t]
  \centering
  \begin{tabular}[t]{l|ll}
    &	$-r$	&	$+r$			\\
    \hline
    $-o$	&	\SUBJ	&	\OBLTHETA	\\
    $+o$	&	\OBJ	&	\OBJTHETA
  \end{tabular}%
  \caption{Feature decomposition of grammatical functions}
  \label{tab:feature-decomposition}
\end{table}
%
% Grammatical functions can now be described in terms of two features: \SUBJ is
% $[-r, -o]$, \OBJ is $[-r, +o]$, \OBLTHETA is $[+r,-o]$, and \OBJTHETA is
% $[+r, +o]$.%
Grammatical functions can now be described in terms of two features: \SUBJ is
{$[-r, -o]$}, \OBJ is {$[-r, +o]$}, \OBLTHETA is {$[+r, -o]$},
and \OBJTHETA is {$[+r, +o]$}.%
%
\footnote{If we take this feature decomposition literally, then grammatical functions are no longer primitives in the theory; instead, the features are. \citet[31]{Butt1995} makes this claim explicitly. However, it is also possible to avoid this conclusion, and retain the primitive status of grammatical functions in LFG, by viewing such feature decomposition as merely descriptive, so that it cross-classifies the GFs but does not formally break them down (\citealp[298ff.]{butt1997architecture,findlay2017mapping}{}; see Section~\ref{sec:argstr:nature-of-mapping} below).}
%
Each individual feature can also be used to describe a pair of GFs, as seen in each of the two rows and two columns of Table~\ref{tab:feature-decomposition}. This is what enables the association of an argument with a limited natural class of GFs: in Classical LMT, arguments are linked to a single feature (by means to be explored in the next section), and thereby made compatible with two GFs. This is more permissive than the original LFG approach, where an argument is linked to a specific GF, but still limited: argument alternations can only map the argument to the \emph{other} GF, not to any arbitrarily different GF.

\citet[25]{bresnan1989locative} claim that the pairings induced by the feature decomposition just described are natural classes. This is a large part of the explanatory appeal of Classical LMT, so it is worth dwelling on momentarily. In fact, this is an area where Classical LMT has received some criticism. \citet{alsina1996the-role}, for example, observes that the standard feature decomposition fails in both directions: it describes an unnatural class and also fails to capture an important natural one. The pair of GFs described by $[+r]$, namely \OBJTHETA and \OBLTHETA, does not seem to form a natural class, in that there are no instances where arguments alternate between them. At the same time, the division between terms\slash direct GFs and nonterms\slash obliques has a number of linguistic reflexes \citep[15--17]{DLM:LFG}, yet no single feature can pick out the terms, i.e. \SUBJ, \OBJ, and \OBJTHETA, or the nonterms, i.e. \OBLTHETA \citep[29, fn.~9]{alsina1996the-role}. For this reason, \citet[19--20]{alsina1996the-role} suggests a different decomposition, according to the features $[\pm\textnormal{subj}]$ and $[\pm
\textnormal{obl}]$.

On a related note, \citet[130]{Findlay2020} and \citet[32]{asudeh:unrealized} object to
the ``suspiciously circular'' (\textit{ibid.}) definition of $[\pm o]$. While it
might be relatively clear what independent content $[\pm r]$ could have (being
semantically restricted makes sense outside of the context of grammatical
functions), it is much less clear what independent content $[\pm o]$ could
possess: it identifies a GF as belonging or not to the set \{\OBJ,
\OBJTHETA{}\}, but by virtue of no other property than membership of that set.

Despite these qualms, the cleavages induced by the $[r]$ and $[o]$ features
remain in common usage, even if their interpretation is reimagined (e.g.
\citealt[266]{kibort14} views $[+o]$ as picking out the complements from the
non-complements, and $[-r]$ as picking out the core arguments from the non-core
-- see Section~\ref{sec:argstr:morphosemantic-alternations}). The most significant
reason for this is ultimately their success: the cross-classification in
Table~\ref{tab:feature-decomposition} has proved incredibly useful in describing
a variety of argument structure phenomena in a diverse selection of languages --
we will see some examples of this later in this section and especially in
Section~\ref{sec:argstr:lmt-case-studies}.
% In what follows, we will therefore continue
% to assume the relevance of these mapping features.

One potential immediate issue is that using two binary-valued features enables us
to describe a four-way classification, but LFG's inventory of grammatical
functions has more than four members. Of course, it is no problem that we omit
\ADJ and \XADJ from consideration, since adjuncts are not involved directly in
argument structure and mapping, being unable (by definition) to be selected by a
predicate.%
%
\footnote{In fact, it has been argued that there are such things as ``obligatory
  adjuncts'', given the existence of contrasts like the following, where the
  omission of the parenthetical material leads to ungrammaticality on the
  intended reading of the verb:

  \ea
  \ea
  Cat behaves *(badly).
  \ex
  Lister lives *(in space).
  \ex
  This book reads *(well).
  \z
  \z
  %
  See \citet[262--263]{Przep16} and references therein for further discussion
  and exemplification.}
%
However, the two clausal GFs \COMP and \XCOMP, both argument GFs, are also
missing from Table~\ref{tab:feature-decomposition}. In fact, and despite some
countervailing voices \citep{DL00,Lodrup2012}, many researchers have advocated
for eliminating these GFs by assimilating them to one or more of the other
complement GFs, \textit{viz.} \OBJ, \OBJTHETA, and \OBLTHETA
(\citealp[197--198]{zaeneng94},
\citealp{alsina1996the-role,AMM05,forst06,berman2007,patejuk2016reducing,Szucs2018}).
In that case, the omission of \COMP and \XCOMP from
Table~\ref{tab:feature-decomposition} is not a problem. Even if the clausal GFs
are not eliminated entirely, it seems possible that the distinction between them
and the other complement GFs could still be neutralised at the level of
specificity required of mapping theory. We can therefore continue to assume that
the four GFs in Table~\ref{tab:feature-decomposition} are the only ones relevant
for mapping.

Besides dividing up the GFs, the $[r]$ and $[o]$ features can also be used to
order them. \citet[49]{bresnanzaenen90} claim that the features indicate
markedness of GFs, so that those which possess more negative-valued features are
less marked than those which possess more positive-valued ones. This leads to
the partial ordering known as the \fm{Markedness Hierarchy}:

\begin{exe}
\ex \label{markednesshierarchy}
\textit{The Markedness Hierarchy:}\\
$\SUBJ > \OBJ, \OBLTHETA >  \OBJTHETA$
\end{exe}
%
\SUBJ, bearing a negative value for both features, is the least marked GF, at
the top of the hierarchy; \OBJTHETA, with two positive values, is the most
highly marked, at the bottom. Since \OBJ and \OBLTHETA both have one negative-
and one positive-valued feature, they sit in the middle, and are not ordered
with respect to one another.%
%
\footnote{Note that the order of GFs in this hierarchy differs from the
  typologically-motivated Functional Hierarchy, which \citet[11]{DLM:LFG}
  present as the standard in LFG (based on the Accessibility Hierarchy of
  \citealt{keenan1977noun}):

  \begin{exe}
    \ex \label{functionalhierarchy}\textit{The Functional Hierarchy:}\\
    $\SUBJ > \OBJ > \OBJTHETA\ (> \XCOMP, \COMP) > \OBLTHETA\ (> \XADJ, \ADJ)$ \label{ex:functional-hierarchy}
  \end{exe}
%
  Notably, \OBJTHETA outranks \OBLTHETA in (\ref{functionalhierarchy}), while
  the opposite is true in (\ref{markednesshierarchy}).}
%
This hierarchy of GFs is important for the principles which Classical LMT uses
to determine the ultimate mapping of arguments to GFs, to which we now turn.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Initial classification and mapping of
  arguments}\label{sec:argstr:lmt-initial}

Just as in Section~\ref{sec:argstr:lexical-rules}, we assume that predicates are
equipped with an argument structure that lists their syntactically-realisable
arguments. (\ref{ex:kick-arg-struc-plain}) shows a simple example for
\textit{kick}:

\ea\label{ex:kick-arg-struc-plain}
\begin{tabular}[t]{rcccc}
  \textit{kick} & $\langle$  & Agent  & Patient   & $\rangle$\\
\end{tabular}
\z
%
Although Classical LMT still offers no formal consensus on its status or
position in the architecture of LFG, such a list now starts to be referred to as
\fm{\astruc}, as if it were a separate level of the parallel projection
architecture (see \citealt[97--106]{falk2001lexical} for some discussion).
Arguments within \astruc{} are ordered according to their thematic role,
following the thematic hierarchy introduced in (\ref{ex:thematic-hierarchy}),
and repeated in (\ref{ex:thematic-hierarchy-repeat})
\citep[23]{bresnan1989locative}:

\ea\label{ex:thematic-hierarchy-repeat}
\textit{The Thematic Hierarchy:}\\
Agent $>$ Beneficiary $>$ Recipient\slash Experiencer\\%
\hfill $>$ Instrument $>$ Theme/Patient $>$ Location%
\z
%
The most important function of this ranking in Classical LMT is simply to
identify the most highly ranked argument, which we refer to as $\hat{\theta}$.%
%
\footnote{This is also sometimes called the \fm{thematic subject} or
  \fm{a-structure subject}, and has also been equated with the concept of
  \fm{logical subject}. Such a notion of ``most thematically prominent
  argument'' has been shown to play a role outside of mapping theory as well,
  such as in determining the antecedent of a reflexive
  \citep{dalrymple1993,Joshi93,MohananT1994,manning:dissociations}.}
%
This is because of the observation that the most ``prominent'' thematic role
often aligns with the most ``prominent'' GF, i.e. \SUBJ
\citep{fillmore:case,Grimshaw90,speas1990}. We will see how this is cashed out
in Classical LMT below.

Whereas arguments were previously associated with a specific GF in the lexicon,
in Classical LMT they are associated with a single $[\pm o/r]$ feature instead
(i.e. with a \emph{pair} of GFs). In early versions of LMT, such as
\citet[25--26]{bresnan1989locative} or \citet{BresMosh90}, this is achieved by
intrinsic connections between specific named thematic roles and features, as in
(\ref{intrinsicclass}), from \citet[168]{BresMosh90}:

% \ea \label{intrinsicclass}
% \textit{Intrinsic classifications:}\\
% \begin{tabular}{lll}
%  \maplink{Agent}{$[-o]$}&
% \maplink{Theme/Patient}{$[-r]$}&
%  \maplink{Location}{$[-o]$}
% \end{tabular}
% \z
\ea \label{intrinsicclass}
\textit{Intrinsic classifications:}\\[0.5ex]
\begin{tabular}{@{}ccc}
  Agent & Theme\slash Patient & Location\\
  $[-o]$& $[-r]$ & $[-o]$
\end{tabular}
\z
%
This is based on typological observations about common realisations of various
thematic roles across languages: cross-linguistically, for instance,
Themes\slash Patients canonically alternate between the unrestricted GFs, i.e.
subject and object, while other roles like Agent and Location canonically
alternate between the non-object functions, i.e. subject and oblique
\citep[26]{bresnan1989locative}. There is no principled limit on which roles
might receive intrinsic classifications like this.

In subsequent work in Classical LMT, this open-endedness is rejected, and the
initial classification principles are reduced to three
(\citealp[49]{bresnanzaenen90}; cf.~also \citealt{Her2003,Her2013}; and see
\citealt[331]{BresnanEtAl2016} for a contemporary textbook presentation),
claimed to be general across languages:%
%
\footnote{``$\theta$'' is used to stand for any thematic role, since these
  principles no longer refer to specific roles. }
%

% \ea\label{ex:new-intrinsic}
% \begin{tabular}[t]{ll}
%   patientlike roles: & \maplink{$\theta$}{$[-r]$}  \\
%   secondary patientlike roles: & \maplink{$\theta$}{$[+o]$} \\
%   other roles: & \maplink{$\theta$}{$[-o]$}
% \end{tabular}
% \z
%
\ea\label{ex:new-intrinsic}
\textit{Intrinsic classifications (general):}\\[0.5ex]
\begin{tabular}[t]{@{}ccc}
  patientlike roles: & secondary patientlike roles: & other roles:\\[0.5ex]
  $\theta$ & $\theta$ & $\theta$\\
  $[-r]$ & $[+o]$ & $[-o]$
\end{tabular}
\z
%
While this is an improvement in terms of theoretical parsimony, there is a cost
in terms of explicitness. \citet[32]{asudeh:unrealized}, for instance, complains
that the notion of being ``patientlike'' is ``obscure'', noting that ``its not
clear what the conditions are for meeting the criterion of being `like' a
patient''.

Let us assume, however, that it is clear enough when a role is patientlike or
not. What of the secondary patientlike roles? Where verbs have more than one
patientlike argument, as in ditransitives, one of the two may be ``secondary''
in the sense of \citet{dryer:objects}, and this argument will be marked as
$[+o]$. Such languages are called \fm{asymmetrical object languages}, in
contrast with \fm{symmetrical object languages}, which permit multiple
patientlike roles to be marked $[-r]$ (see \citealt{BresMosh90} and
Section~\ref{sec:argstr:double-object} below). Even within asymmetrical object
languages, there is variation in which of the two arguments counts as primary or
secondary -- indeed, a single language can permit both possibilities (see
discussion of English \textit{give} below).

Given these basic assignments, the \astruc{} of our simple transitive verb
\textit{kick} will be as follows:

\ea\label{ex:kick-astruc}
\begin{tabular}[t]{lrccl}
  \textit{kick}&$\langle$ & Agent & Patient & $\rangle$\\
  &&$[-o]$&$[-r]$
\end{tabular}
\z
%
There is one patientlike role, namely the Patient itself, so this is marked
$[-r]$; the one other role is marked $[-o]$, according to the third,
``elsewhere'' principle in (\ref{ex:new-intrinsic}).

To resolve these single features to fully-specified GFs, Classical LMT makes use
of two \fm{Mapping Principles}:%
%
\footnote{We follow the formulation of \citet[334]{BresnanEtAl2016}; for the
  first appearance of these principles, see \citet[51]{bresnanzaenen90}.}
%

\ea\label{ex:mapping-principles}%
\textit{Mapping Principles}:%
\ea%
Subject roles:%
\ea
\begin{tabular}[t]{c}
  $\hat\theta$\\$[-o]$
\end{tabular}
is mapped onto \SUBJ when initial in the
\astruc{};\\[1.5ex]%
otherwise:%
\ex
\begin{tabular}[t]{c} $\theta$ \\ $[-r]$ \end{tabular}
% \maplink{$\theta$}{$[-r]$}
is mapped onto \SUBJ.\\[1.5ex]%
\z%
\ex%
Other roles are mapped onto the lowest featurally compatible function on the
Markedness Hierarchy in (\ref{markednesshierarchy}).
% Non-subject mapping principle: Map other roles to lowest compatible function on markedness hierarchy.
\z
\z
%
\largerpage
As mentioned, the most thematically prominent argument, $\hat\theta$, is strongly associated with the \SUBJ position; Mapping Principle (a-i) captures this, and requires that a non-patientlike $\hat\theta$ maps to \SUBJ where possible. The constraint that $\hat\theta$ be leftmost in the \astruc{} is to account for the presence of non-thematic arguments which might take precedence in mapping to \SUBJ. For example, the \astruc{} of a raising verb like \textit{seem} is as shown in (\ref{ex:seem-arg-struc}) \citep[200]{zaeneng94}:
% \citealp[332]{BresnanEtAl2016}):

\ea\label{ex:seem-arg-struc}
\begin{tabular}[t]{lcrcl}
  \textit{seem}& \_\_ & $\langle$ & Proposition & $\rangle$\\
  & $[-r]$ & &$[-o]$
\end{tabular}
\z
%
Although \textit{seem} only takes a single semantic argument, the Proposition it
embeds, this argument cannot surface as the subject, and the verb instead takes
a non-thematic, expletive subject:%
%
\footnote{Of course, there is also the ``raised'' alternative \textit{Kira
    seemed to smile}. See \citet{zaeneng94} and \citet[ch.~15]{DLM:LFG} for the
  treatment of raising in LFG.}
%

\ea
\ea[*]{That Kira smiled seemed.}\label{ex:bad-seem}
\ex[]{It seemed that Kira smiled.}\label{ex:good-seem-it}
% \ex[]{Kira seemed to smile.}\label{ex:good-seem-raised}
\z
\z
%
For this reason, (\ref{ex:seem-arg-struc}) contains two argument slots, although
one is devoid of semantic content and is therefore marked as $[-r]$, since a
non-thematic argument, by definition, cannot be semantically restricted. The
highest thematic role, $\hat\theta$, is still the Proposition, and it is marked
$[-o]$, but because it is no longer initial in the \astruc, it is not mapped to
\SUBJ by Mapping Principle (a-i), leaving the expletive argument available to
map to \SUBJ by Principle (a-ii).

In addition to the Mapping Principles in (\ref{ex:mapping-principles}), there
are two other well-formed\-ness conditions on mapping, \fm{Function-Argument
  Biuniqueness} \citep[112]{bresnan:polyadicity}, and the \fm{Subject
  Condition} \citep[28]{baker83,bresnan1989locative}:%
%
\footnote{Once again, we take the specific wording from
  \citet[334]{BresnanEtAl2016}.}
%

\ea
\textit{Function-Argument Biuniqueness:}\\
Each \astruc{} role must be associated with a unique function, and vice versa.
\ex
\textit{The Subject Condition:}\\
Every predicator must have a subject.%
\z
%
The first condition ensures that a predicate cannot select for multiple of the
same GF, and that a single argument cannot be realised by multiple GFs of the
same predicate.%
%
\footnote{The first part of this is already barred by the \fstruc{}
  well-formedness condition called Consistency \citep[53--54]{DLM:LFG}, which
  follows from the functional nature of \fstruc: each attribute at \fstruc, such
  as a GF like \SUBJ or \OBJ, can only have a single value.\label{fn:consistency}}
%
The second represents a supposed language universal, that all predicates possess
subjects -- even when these are not overtly expressed. There have been some
doubts about the universality of this claim (see e.g. \citealt[28,
fn.~37]{bresnan1989locative}, \citealt[334, fn.~9]{BresnanEtAl2016},
\citealt{Kibort2006}, and references therein), so it may be more appropriate to
see this as a parameter which varies by language.%
%
\footnote{\citet[358--359]{Kibort2004} reworks the Classical LMT Mapping
  Principles in such a way that she can do without the Subject Condition
  altogether -- see Section~\ref{sec:argstr:morphosemantic-alternations} for more
  details.}
%

Note that these well-formedness conditions are more important in early LMT work,
such as \citet{bresnan1989locative}, since this version of the theory does not
include explicit Mapping Principles like (\ref{ex:mapping-principles}). Instead,
through a richer theory of intrinsic and default assignment of features to
arguments, a number of mappings are made possible, which are then filtered down
to the unique solution by Function-Argument Biuniqueness and the Subject
Condition \citep[28ff.]{bresnan1989locative}. In the sense that this involves
positing fewer rules, it is a simpler theory -- but the rules it does include
are more specific (i.e. referring to particular thematic roles by name), making
it less general overall.

Let us return now to the example of a simple transitive predicate like
\textit{kick} and see how the Mapping Principles apply in practice. Since Agent
outranks Patient on the Thematic Hierarchy, the Agent is identified as
$\hat\theta$; since this argument is also initial in the \astruc, it is
therefore mapped to \SUBJ. The remaining argument, the $[-r]$ Patient, then maps
to the lowest compatible GF on the Markedness Hierarchy: the lowest $[-r]$ GF is
\OBJ. This correctly gives us the active voice mapping whereby the Agent is
realised as the subject, and the Patient as the object:

\ea\label{ex:kick-astrucmapping}
\begin{tabular}[t]{lrccl}
  \textit{kick}&$\langle$ & Agent &
                                    Patient & $\rangle$\\
               &&\maplink{$[-o]$}{\SUBJ} &  \maplink{$[-r]$}{\OBJ}
\end{tabular}
\z

What of other predicate types?%
%
\footnote{We consider only verbal predicates in this chapter. This footnote
  offers a selection of references for the reader interested in learning more
  about argument structure and mapping phenomena within the nominal domain. The
  most prominent idea, proposed by \citet{Rappaport83}, is that nominals derived
  from verbs inherit that verb's argument structure, but that the possibilities
  for mapping are more constrained within the noun phrase -- for example, the
  functions \SUBJ and \OBJ are not available to the dependents of nouns (cf.
  \textit{Luke destroyed the Death Star} and \textit{Luke's destruction of the
    Death Star}). This perspective remains the dominant one -- see e.g.
  \citet{Laczko00,Laczko01,Laczko07,kelling2003,ChisaPayn01,ChisaPayn03} -- but
  some have instead argued that nominals either don't have argument structures,
  or that, where they do, they can differ from the corresponding verbal ones
  \citep{ramchand97, Lowe17, taylorphd2023}. \textcitetv{chapters/Nominal} 
  provide a useful contemporary summary of the issues.

  A wide range of languages have been studied in LFG with respect to nominal
  argument structures and their mapping possibilities: see
  %
  \citet{Saiki1987} on Japanese,
  \citet{Markantonatou1995} on Modern Greek,
  \citet{Laczko00,Laczko01,Laczko2004,Laczko10} on Hungarian,
  \citet{Falk01actnom} on Modern Hebrew,
  \citet{kelling2003} on French,
  \citet{sulger2012} on Hindi-Urdu,
  \citet{Lowe17} on Sanskrit and other early Indo-Aryan languages,
  and
  \citet{taylorphd2023} on Old English.
  % \citet{ramchand97} on Scottish Gaelic, % Not LMT
  }
%
Intransitives should have their single argument
mapped to \SUBJ. The initial feature assignment to this argument will depend on
whether the predicate is unaccusative or unergative \citep{Perlmutter1978}:
since the single argument of an unaccusative is patientlike, it will be assigned
$[-r]$; unergatives, on the other hand, have more agentlike arguments, which
will therefore be assigned $[-o]$. However, in both cases this will result in
the correct mapping (in the simple, active case): for the unaccusative verb,
(\ref{ex:unaccusative-simple-argstruc}), Mapping Principle (a-ii) applies, while
for the unergative (\ref{ex:unergative-simple-argstruc}), Principle (a-i) does
the job.

\ea\label{ex:unaccusative-simple-argstruc}
\begin{tabular}[t]{lrcl}
  \textit{fall}& $\langle$ & Patient & $\rangle$\\
               &&\maplink{$[-r]$}{\SUBJ}
\end{tabular}
\ex\label{ex:unergative-simple-argstruc}
\begin{tabular}[t]{lrcl}
  \textit{run}& $\langle$ & Agent & $\rangle$\\
              &&\maplink{$[-o]$}{\SUBJ}
\end{tabular}
\z

Ditransitives like \textit{give} are slightly more complicated. They of course
have three arguments in their \astruc:

\ea\label{ex:give-astruc-initial}
\begin{tabular}[t]{lrcccl}
\textit{give}&$\langle$ & Agent & Beneficiary/Recipient & Theme & $\rangle$
\end{tabular}
\z
%
Following the usual initial classifications, the Theme, as a patientlike
argument, is linked to $[-r]$, and the Beneficiary/Recipient and Agent both
receive the ``elsewhere'' $[-o]$ feature. As per the Mapping Principles, the
Agent, an \astruc-initial, $[-o]$-valued, $\hat\theta$ argument, is mapped to
\SUBJ. The Beneficiary\slash Recipient maps to the lowest $[-o]$ GF, which is
\OBLTHETA, while the Theme maps to the lowest $[-r]$ GF, \OBJ. This gives us one
correct mapping for \textit{give}, illustrated in a sentence like \textit{Peter
  gave a present to Harriet}.

\ea\label{ex:give-astruc-intrinsic-non-shifted}
\begin{tabular}[t]{lrcccl}
  \textit{give}&$\langle $ & Agent &
                                     Beneficiary/Recipient & Theme & $\rangle$\\
               && \maplink{$[-o]$}{\SUBJ} & \maplink{$[-o]$}{\OBLTHETA} & \maplink{$[-r]$}{\OBJ}
\end{tabular}
\z
%

But of course there is another way of realising the arguments of a ditransitive
like \textit{give}: the dative-shifted version, illustrated in \textit{Peter
  gave Harriet a present}. Since this involves the same thematic roles, this
alternation cannot be derived in Classical LMT without some further stipulation
\citep[314]{Kibort:08}. It seems that we can choose to view the
Beneficiary\slash Recipient as patientlike \citep[cf.][]{toivonen:benefactives},
in which case it is assigned $[-r]$ by the intrinsic classification rules
(\citealp[14--15]{bresnan:lexical-syntax}; cf. also
\citealp[337--340]{BresnanEtAl2016}). Now, English is an asymmetrical object
language, which means it does not permit the presence of two $[-r]$ arguments at
\astruc\ (see Section~\ref{sec:argstr:double-object}), and so the (lower-ranked) Theme
must instead be marked $[+o]$, as a secondary patientlike argument, per
(\ref{ex:new-intrinsic}). The Agent receives the ``elsewhere'' $[-o]$
specification as usual, giving us the following \astruc\ and GF-mapping:

\ea\label{ex:give-astruc-intrinsic-shifted}
\begin{tabular}[t]{lrcccl}
  \textit{give}&$\langle$ & Agent &
                                    Beneficiary/Recipient & Theme & $\rangle$\\
               &&\maplink{$[-o]$}{\SUBJ} & \maplink{$[-r]$}{\OBJ} & \maplink{$[+o]$}{\OBJTHETA}
\end{tabular}
\z
%
This is the double object version of \textit{give}: the Agent is mapped to \SUBJ
as usual, then the other arguments are mapped to the lowest compatible GFs, in
this case \OBJ for the Beneficiary/Recipient (the lowest $[-r]$ GF) and
\OBJTHETA for the Theme (the lowest $[+o]$ GF). So, Classical LMT can account
for the dative shift alternation, but only with the initial stipulation that the
Beneficiary/Recipient can be viewed as patientlike, and hence assigned $[-r]$ at
\astruc. Indeed, morphosemantic alternations in general are problematic for
Classical LMT, a shortcoming which \citet{Kibort2007,kibort14} attempts to
rectify, and which we will examine in more detail in
Section~\ref{sec:argstr:morphosemantic-alternations}. For now, though, we consider the
well-developed Classical LMT account of (morphosyntactic) alternations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Argument alternations}\label{sec:argstr:arg-alternations-in-lmt}
Argument alternations in Classical LMT are handled by adding extra
specifications to arguments -- in this way information is only added, not
removed, meaning that ``the computational requirement of monotonicity can be met
even in the domain of relation changes'' \citep[650]{Bresnan:Monotonicity}.

One common mechanism is that of \fm{suppression}, illustrated schematically in
(\ref{ex:suppression}):

\ea\label{ex:suppression}%
\maplink{$\theta$}{$\varnothing$}%
\z
%
This prevents an argument from being mapped to a GF at \fstruc, and
existentially quantifies over the argument in the semantics (though it does
allow the possibility of the argument being realised by an adjunct, like the
English \textit{by}-phrase which can express the Agent of a passive, so this
quantification only applies if the argument remains unexpressed). Suppression is
restricted to unmarked arguments, i.e. those pre-specified with a
negatively-valued feature at \astruc\ (\citealp{Alsina1999}; see also
\citealt[338--340]{BresnanEtAl2016} for a relevant example), a principle known
as \fm{Recoverability of Suppresion} \citep[333]{BresnanEtAl2016}.

Lexical rules involving deletion can be recast in terms of suppression. For
example, instead of deleting an \OBJ, as in (\ref{ex:intransitivisation-rule}),
intransitivisation involves suppression of a Theme\slash Patient argument:

\ea\label{ex:intransitivisation-classical-lmt}
\begin{tabular}[t]{ll}
  Intransitivisation: & \maplink{Theme\slash Patient}{$\varnothing$}
\end{tabular}
\z
%
And rather than deleting or re-writing the \SUBJ and changing an \OBJ to a
\SUBJ, as in (\ref{universalpassiverule}), passivisation simply involves a
single process, \textit{viz.} the suppression of the highest thematic role:

\ea\label{ex:passive-classical-lmt}
\begin{tabular}[t]{ll}
  Passivisation: & \maplink{$\hat{\theta}$}{$\varnothing$}
\end{tabular}
\z
%
This simplified analysis of passivisation works because of the general system of
mapping assumed in Classical LMT. In a standard two-place predicate like
\textit{kick}, the highest, Agent argument will be $[-o]$, while the next,
Patient argument will be $[-r]$. If the Agent argument is suppressed, Mapping
Principle (a-i) will not apply, and instead Principle (a-ii), which maps a
$[-r]$ argument to \SUBJ, will step in, correctly promoting the Patient
argument, without any need for further stipulation:%
%
\footnote{The way the Mapping Principles are written, it seems to us that
  argument suppression should lead to a contradiction. Assuming the Principles
  are intended to be declarative rather than procedural, then
  (\ref{ex:kick-astruc-passive}) would seem to violate Mapping Principle (a-i),
  since it is not true that a $[-o]$, \astruc-initial $\hat\theta$ is mapped
  onto \SUBJ: instead, it is not mapped to anything; and the same goes for
  intransitivisation: the suppressed Theme\slash Patient argument in a
  transitive will not be mapped to the lowest featurally compatible function on
  the Markedness Hierarchy, contrary to Principle (b). Perhaps suppression
  removes an argument from consideration at \astruc\ altogether, but in that case
  it would not be monotonic. One solution would simply be to add the rider
  ``unless suppressed'' to each of the Mapping Principles, but this seems far
  from parsimonious.\label{fn:suppression}}
%

\ea\label{ex:kick-astruc-passive}
\begin{tabular}[t]{lrccl}
  \textit{kicked}\textsubscript{\textsc{passive}}&$\langle$ & Agent & Patient & $\rangle$ \\
                                      &&\maplink{$[-o]$}{$\varnothing$} & \maplink{$[-r]$}{\SUBJ}
\end{tabular}
\z

Passivisation also correctly applies to ditransitives in both their
\astruc{} realisations. For example, suppressing the Agent in the non-shifted
version, repeated in (\ref{ex:give-astruc-intrinsic-non-shifted-mapping}),
results in the Theme being promoted to \SUBJ, by Mapping Principle (a-ii), since
it is a $[-r]$ argument.

\ea\label{ex:give-astruc-intrinsic-non-shifted-mapping}
\begin{tabular}[t]{lrcccl}
  \textit{give}&$\langle$ & Agent &
                                    Beneficiary/Recipient & Theme & $\rangle$\\
               &&\maplink{$[-o]$}{$\varnothing$}&\maplink{$[-o]$}{\OBLTHETA}&\maplink{$[-r]$}{\SUBJ}
\end{tabular}
\z
%
This gives us the correct alternation, illustrated in
(\ref{ex:non-shifted-passive}), where the Beneficiary\slash Recipient remains an
\OBLTHETA (since this is still the most marked $[-o]$ GF):

\ea\label{ex:non-shifted-passive}
\ea Peter gave a present to Harriet.
\ex A present was given to Harriet (by Peter).
\z
\z
%
On the other hand, when the Agent is suppressed in the dative-shifted version,
the Beneficiary\slash Recipient is promoted instead, since it is now the $[-r]$
argument, while the Theme remains an \OBJTHETA (since this is still the most
marked $[+o]$ GF):%

\ea\label{ex:give-astruc-intrinsic-shifted-mapping}
\begin{tabular}[t]{lrcccl}
  \textit{give}&$\langle$ & Agent &
                                    Beneficiary/Recipient & Theme & $\rangle$\\
               &&\maplink{$[-o]$}{$\varnothing$} & \maplink{$[-r]$}{\SUBJ} & \maplink{$[+o]$}{\OBJTHETA}
\end{tabular}
\z
%
This again accords with the facts:%
%
\footnote{For those dialects where \textit{\%A present was given Harriet (by
    Peter)} is grammatical, something more needs to be said, of course. It is
  possible the Asymmetrical Object Parameter \citep{BresMosh90} is not in force
  in these varieties of English (see Section~\ref{sec:argstr:double-object} for more
  on the AOP).}
%

\ea Peter gave Harriet a present.\label{ex:give-shifted}
\z
\ea Harriet was given a present (by Peter).\label{ex:obj-theta-passive}
\z

Notice that because Mapping Principle (b) requires that an argument be map\-ped to
the \emph{lowest} compatible GF on the hierarchy, the $[+o]$ argument of such
double object verbs remains an \OBJTHETA\ in the passive, and is not, for
example, ``promoted'' to \OBJ. That this is the correct result is not at all
obvious from English data alone: the usual test for \OBJ-hood is the possibility
of promotion through passivisation, but we cannot passivise a passive. In the
absence of any morphological marking of the distinction between \OBJ and
\OBJTHETA, there is no obvious way to tell which of these two GFs \textit{a
  present} bears in example (\ref{ex:obj-theta-passive}).

Data from other languages, however, such as the Bantu language Chiche\^{w}a,
support the Classical LMT analysis. Ditransitive verbs can be formed in
Chiche\^{w}a by applicativisation, and when the applied argument is a
Beneficiary, it is assigned a $[-r]$ classification at \astruc, while the Theme
is assigned $[+o]$, exactly as in the English double object construction, and
resulting in the same GF assignments as we saw above
\citep[28]{AlsinaMchombo:Appl}. In such Chiche\^wa applicatives, only the \OBJ
(the Beneficiary) can be indexed by an object marker on the verb, while the
\OBJTHETA (the Theme) cannot (\citealp{BresMosh90};
\citealp[22]{AlsinaMchombo:Appl}):%
%
\footnote{Object NPs indexed on the verb can be omitted, indicated here by
  parentheses. Numbers signify noun classes; \textsc{s} = subject marker;
  \textsc{o} = object marker; \textsc{fv} = final vowel.}
%

\ea
\ea[]{
  \gll Chi-ts\^iru chi-na-w\'a-g\'ul-ir-\'a m-ph\^atso (a-ts\'ik\=ana).\\
  7-fool 7\textsc{s}-\PST-2\textsc{o}-buy-\APPL-\textsc{fv} 9-gift 2-girls\\
  \glt `The fool bought a gift for them (the girls).'
}
\ex[*]{
  \gll Chi-ts\^iru chi-na-\'i-g\'ul-ir-\'a a-ts\'ik\=ana (m-ph\^atso).\\
  7-fool 7\textsc{s}-\PST-9\textsc{o}-buy-\APPL-\textsc{fv} 2-girls 9-gift\\
  }
\z
\z
%
Now, given the \astruc\ assignments, we also observe the same passivisation
pattern for Chiche\^wa applicatives as for the English double object
construction, with the Beneficiary \OBJ being promoted to \SUBJ
\citep[29]{AlsinaMchombo:Appl}:

\ea
\gll Ats\'ik\=ana  a-na-ph\'ik-\'ir-idw-\'a ny\^emba.\\
2-girls 2\textsc{s}-\PST-cook-\APPL-\PASS-\textsc{fv} 10-beans\\
\glt `The girls were cooked beans.'
\z
%
Crucially, we now have a diagnostic to identify the GF of the remaining Theme
argument: if it is promoted to \OBJ, it should be compatible with the presence
of an agreeing object marker on the verb; if it remains an \OBJTHETA, then the
use of the object marker will not be possible. In fact, use of the object marker
in this construction is ungrammatical \citep[30]{AlsinaMchombo:Appl}:

\ea[*]{
\gll Ats\'ik\=ana  a-na-z\'i-ph\'ik-\'ir-idw-\'a (ny\^emba).\\
2-girls 2\textsc{s}-\PST-10\textsc{o}-cook-\APPL-\PASS-\textsc{fv} 10-beans\\
 \glt `The girls were cooked beans.'
}
\z
%
This incompatibility shows that the Beneficiary argument here must still be an
\OBJTHETA, not an \OBJ, and this therefore motivates Mapping Principle (b),
where arguments are linked to the \emph{most} marked compatible GF (though the
empirical landscape may not be quite so straightforward as this single data
point would suggest: see \citealt{Kibort:08} for some discussion of the
complexities).

% Evidence from Bantu languages like this was central to the development of
% Classical LMT, but it appears to have been overlooked in later versions of
% mapping theory: approaches such as those discussed in
% Sections~\ref{sec:argstr:optimal-linking} and \ref{sec:argstr:kibort-lmt} below make the wrong
% prediction, that the Theme is promoted to \OBJ in the passive (see further
% discussion in those sections).

Along with suppression, argument alternations can involve adding new arguments
to an \astruc, as in the Bantu applicative \citep{BresMosh90}, or the English
benefactive \citep{toivonen:benefactives}. For example,
\citet[514]{toivonen:benefactives} gives the rule in (\ref{ex:benefactive-rule})
for the benefactive in English, which takes a transitive verb into a
ditransitive, as in (\ref{ex:benefactive-alternation}):

\ea\label{ex:benefactive-alternation}
\ea
I'll pack some sandwiches.
\ex
I'll pack the children some sandwiches.
\z
\ex\label{ex:benefactive-rule}
English benefactive:
\begin{tabular}[t]{rcccl}
  $\langle$ & $\hat\theta$ &
                             \argumentadd{Beneficiary/Recipient}{$\varnothing$}
  & Theme & $\rangle$\\
            &$[-o]$&$[-r]$& $[+o]$
\end{tabular}
\z
%
Note that the symbol $\varnothing$ is used differently here from above, where it
represented argument suppression. Here it captures the fact that the
Beneficiary\slash Recipient is added to an \astruc\ which otherwise contains
only a Theme and a $\hat\theta$, whatever role that may play; i.e.
(\ref{ex:benefactive-rule}) adds the Beneficiary\slash Recipient where
previously there was no argument.

As well as adding or suppressing arguments, alternations can also involve
constraining the mapping possibilities of arguments. This is what happens in
locative inversion, for example. The relevant examples from Chiche\^wa are
repeated in (\ref{ex:locative-inversion-repeat}):

\ea\label{ex:locative-inversion-repeat}
\ea\label{ex:li-repeat-uninverted}
\gll Chi-ts\^{i}me chi-li    ku-mu-dzi. \\
7-well        7-be 17-3-village\\
\glt `The well is in the village.'\\[0.5em]
%
\ex\label{ex:li-repeat-inverted}
\gll Ku-mu-dzi     ku-li       chi-ts\^{i}me. \\
17-3-village  17-be  7-well\\
\glt `In the village is a well.'%
\z%
\z
%
\citet[27]{bresnan1989locative} analyse the relevant process in the following
terms:

\ea\label{ex:locative-inversion-rule}
\begin{tabular}[t]{lrcccl}
  Locative inversion:
  &$\langle$&Theme&\dots&Location&$\rangle$\\
  &&&&$[-r]$
\end{tabular}
\z
%
That is, when a Location appears in the same \astruc\ as a Theme, assign it the
specification $[-r]$ in addition to whatever its intrinsic feature assignment
is. Let us see how this provides the contrast in
(\ref{ex:locative-inversion-repeat}).

In the relevant sense, the verb \textit{-li} `be' takes a Theme and a Location
argument; as per the intrinsic specifications of (\ref{ex:new-intrinsic}), the
patientlike Theme is assigned $[-r]$ and the other role is assigned $[-o]$. All
things being equal, this will provide the mapping instantiated by
(\ref{ex:li-repeat-uninverted}), where the Theme maps to \SUBJ, by Mapping
Principle (a-ii), and the Location maps to \OBLTHETA, the lowest $[-o]$ GF.

\ea
\begin{tabular}[t]{lrccl}
  \textit{-li}&$\langle$&Theme&Location&$\rangle$\\
              &&\maplink{$[-r]$}{\SUBJ}&\maplink{$[-o]$}{\OBLTHETA}
\end{tabular}
\z
%
When we apply the additional assignment in (\ref{ex:locative-inversion-rule}),
however, things change:

\ea
\begin{tabular}[t]{lrccl}
  \textit{-li}&$\langle$&Theme&Location&$\rangle$\\
              &&$[-r]$&$[-o]$\\
              &&\longmaplink{}{\OBJ}&\maplink{$[-r]$}{\SUBJ}
\end{tabular}
\z
%
Here, the Location argument is fully specified as a \SUBJ, meaning that the
Theme is prevented from also being mapped to \SUBJ, owing to Function-Argument
Biuniqueness. Instead, it must map to the lowest available GF on the Markedness
Hierarchy, namely \OBJ. This gives us the mapping instantiated by
(\ref{ex:li-repeat-inverted}).

This section has served to provide a sampling of the different approaches to
argument alternations in Classical LMT. By suppressing, adding, or further
specifying arguments, the theory can give succinct accounts of a variety of
different phenomena. To the extent that these simple descriptions make the
correct predictions in conjunction with the underlying theory, this also serves
as a vindication of the latter. Of course, we have hardly been able to do
justice to such a rich literature in a handful of pages, but we hope to have
illustrated the key technical points. In the following section, we provide a few
more case studies, further showcasing areas where Classical LMT has provided
elegant and illuminating analyses.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Case studies and extensions}\label{sec:argstr:lmt-case-studies}


The framework of Classical LMT has been shown to offer an elegant solution to
many thorny empirical issues, but it has also sometimes been necessary to expand
or modify the theory in the face of empirical deficiencies or theoretical
shortcomings. In this section, we discuss various topics which showcase the
workings of Classical LMT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Resultatives}

As first observed by \citet{simpson1983resultatives}, resultative predicates in
English can be applied to the objects of transitives or to the subjects of their
corresponding passives, as shown in (\ref{ex:resultatives-transitive}), and to
the subjects of unaccusative intransitives but not of unergatives, as shown in
(\ref{ex:resultatives-intransitive}) \citep[examples from][46]{bresnanzaenen90}:

\ea \label{ex:resultatives-transitive}
\ea[]{We pounded the metal flat.}\label{ex:resultative-obj}
\ex[]{The metal was pounded flat.}\label{ex:resultative-passive}
\z
\z
\ea\label{ex:resultatives-intransitive}
\ea[]{The river froze solid.}\label{ex:resultative-unaccusative}
\ex[*]{The dog barked hoarse.}\label{ex:resultative-unergative}
\z
\z
%
The question then arises: how should we characterise all and only the arguments
which can have resultatives predicated of them?

The generalisation cannot be based on surface grammatical function. For one
thing, the data above show that both subjects and objects can take resultative
predicates. What is more, only some subjects are implicated:
(\ref{ex:resultative-unergative}) is ungrammatical, and
(\ref{ex:resultative-obj}) would be too if it were intended to mean that we
pounded the metal until \emph{we} were flat.

Given the contrast between unaccusative and unergative predicates, we might
think instead to appeal to the thematic role of the arguments in question:
perhaps resultatives can be applied to Themes, and not to Agents? This would
account for the data in
(\ref{ex:resultatives-transitive}--\ref{ex:resultatives-intransitive}), but
unfortunately there are other data which invalidate such a generalisation.
Resultatives can also be applied to non-thematic arguments such as ``fake
reflexives'', illustrated in (\ref{ex:fake-reflexives}), or ``non-subcategorised
objects'' which do not stand in a direct semantic relation to the main verb,
illustrated in (\ref{ex:non-subcat-obj}) \citep[examples
from][47]{bresnanzaenen90}:


\ea\label{ex:fake-reflexives}
\ea The dog barked itself hoarse.
\ex We ran ourselves ragged.
\z

\newpage
\ex\label{ex:non-subcat-obj}
\ea The dog barked us awake.
\ex We ran the soles right off our shoes.
\z
\z

The tools of Classical LMT offer a straightforward solution to this descriptive
challenge: the arguments in question are simply those which are assigned $[-r]$
as their initial feature value at \astruc. For the Themes in
(\ref{ex:resultatives-transitive}--\ref{ex:resultatives-intransitive}), this
follows from their being patientlike, while for the problematic arguments in
(\ref{ex:fake-reflexives}--\ref{ex:non-subcat-obj}) this follows from their
being non-thematic (and so by definition semantically unrestricted). The more
agentive subjects of transitive and unergative verbs will instead by classified
as $[-o]$ by the ``elsewhere'' condition, which sets them apart.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Proto-roles and unaccusativity}\label{sec:argstr:unaccusativity}

Another area where intrinsic classification of argument positions at \astruc\
has proved a more useful discriminator than other notions is in
\citegen{zaenen93} analysis of unaccusativity in Dutch. Before we consider the
data, however, we first introduce Zaenen's innovative approach to intrinsic
feature specification.

Rather than having to decide impressionistically whether an argument is
``patientlike'' or not, in order to decide whether it should be assigned $[-r]$
or $[-o]$ as its initial feature specification at \astruc,
\citet[146--154]{zaenen93} proposes to operationalise \citegen{Dowty1991} notion
of semantic \textsc{proto-role}.

\citet[571--575]{Dowty1991} envisages semantic roles as prototypes: arguments can
possess a number of both proto-agent and proto-patient properties, with their
behaviour depending on the balance between the two groups. This allows a fuzzier
notion of semantic role, and avoids some of the definitional challenges of using
named roles. Proto-agentivity and proto-patientivity are determined by a number
of lexical entailments, including volition, change of state, and movement, which
describe aspects of the relationship between participant and event
\citep[572]{Dowty1991}:

\ea\label{protoagententailments}
\textit{Proto-agent entailments:}\\
\begin{itemize}
  \item volitional involvement in the event or state
  \item sentience (and/or perception)
  \item causing an event or change of state in another participant
  \item movement (relative to the position of another participant)
  \item exists independently of the event named by the verb
\end{itemize}
\z

\newpage
\ea\label{protopatiententailments}
\textit{Proto-patient entailments:} \\
\begin{itemize}
  \item undergoes change of state
  \item incremental theme%
%
        \footnote{\citet[588]{Dowty1991} defines an incremental theme as ``an NP
        that can determine the aspect of the sentence [\dots]; the event is
        `complete' only if all parts of the NP referent are affected (or
        effected)''. For example, in \textit{Chrisjen ate a pistachio}, the
        eating event is only complete once all (edible) parts of the pistachio
        are eaten.}
%
  \item causally affected by another participant
  \item stationary relative to movement of another participant
  \item does not exist independently of the event, or not at all
\end{itemize}
\z


\citet[576]{Dowty1991} uses these proto-properties to determine the assignment
of the subject and object GFs to arguments (the argument with more proto-agent
properties becomes the subject, while the argument with more proto-agent
properties becomes the object), but \citet[149]{zaenen93} instead uses them to
determine the intrinsic feature specification of an argument at \astruc: those
that have more proto-agent properties will be classified as $[-o]$, while those
that have more proto-patient properties will be classified as $[-r]$. This
therefore captures the same general intuition as the Classical LMT intrinsic
assignment principles in (\ref{ex:new-intrinsic}), namely that patientlike
arguments are $[-r]$ and others are $[-o]$, but does so in a way which makes it
more explicit what criteria an argument has to satisfy to count as patientlike.
(Of course, determining whether an argument satisfies the proto-properties can
also sometimes be rather impressionistic, but many are clear-cut enough to at
least afford one an analytical toehold.)

A problem arises when an argument possesses an equal number of proto-agent and
proto-patient properties (including zero). \citet[576]{Dowty1991} proposes that
in this situation both mappings are available. \citet[150]{zaenen93} instead
assumes that in such a case the argument is assigned $[-r]$. This is somewhat
self-serving in that it gives her the correct results for Dutch (see below),
but, as she observes, it does not seem unreasonable that it is precisely in
areas such as this, where the distinctions are less clear-cut, that languages
vary, and so perhaps a degree of arbitrariness is unavoidable.

Let us now turn to the Dutch data which \citet{zaenen93} uses these tools to
analyse. Intransitive verbs in Dutch take different auxiliaries in the compound
past tense depending on whether they are unaccusative or unergative. The
unergatives take \textit{hebben} `have' and the unaccusatives take \textit{zijn}
`be':

\newpage
\ea \textbf{Unergative verbs:}
\begin{xlist}
  \ex%
  \gll Hij heeft/*is gelopen.\\
  he has/is run\\
  \glt `He has run.'
  %
  \ex%
  \gll Ze heeft/*is getelefoneerd.\\
  she has/is telephoned\\
  \glt `She has telephoned.'
  %
\end{xlist}
\z

\ea \textbf{Unaccusative verbs:}
\begin{xlist}
  \ex%
  \gll Ze is/*heeft overleden.\\
  she is/has died\\
  \glt `She has died.'%
  %
  \ex%
  \gll Hij  is/*heeft gevallen.\\
  he is/has fallen\\
  \glt `He has fallen.'

\end{xlist}
\z
%
This also correlates with another contrast: the possibility of using the past
participle as a pre-nominal modifier. This is impossible with the unergative,
\textit{hebben}-taking verbs, but perfectly productive with the unaccusative,
\textit{zijn}-taking verbs:

\ea
\begin{xlist}
  \ex[*]{%
    \gll de gelopen/getelefoneerd man\\
    the run/telephoned man\\}%
  \ex[]{%
    \gll de overleden/gevallen vrouw\\
    the deceased/fallen woman\\
  \glt `the deceased\slash fallen woman'}
\end{xlist}
\z

Now, if the intransitives were the only verbs we had to consider here, then a
semantic explanation would be possible. For one thing, the single argument of an
unaccusative is generally Theme\slash Patient-like. \citet[132--136]{zaenen93}
also discusses other semantic criteria which distinguish the two classes of
verbs. However, a class of transitive verbs (those with an experiencer argument)
also exhibit the same syntactic split, despite having different semantics.
Firstly, some take \textit{hebben} and some take \textit{zijn} in the compound
past tense:

\ea
\begin{xlist}
  \ex
  \gll  Dat is/*heeft me jarenlang goed bevallen.\\
  that is/has me for.years well pleased\\
  \glt `That has pleased me well for years.' %
  % (p. 144)%
  \ex
  \gll Hij heeft/*is me jarenlang gerriteerd.\\
  he has/is me for.years irritated\\
  \glt `He has irritated me for years.'
\end{xlist}
\z
%
And this distinction once again maps onto a difference in the use of the past
participle as a pre-nominal modifier. When the past participles of those verbs
that take \textit{zijn} are used pre-nominally, their head noun can be
understood as the equivalent of their active voice subject, whereas this is not
the case for those that take \textit{hebben}:

\ea[]{\gll het hem goed bevallen boek\\
    the him well pleased book\\
    \glt `the book that pleased him well'}
  % \ex[\#]{de door het boek bevallen jongen.\\
    % the pleased boy}
\z

\ea
\begin{xlist}
  \ex[]{\gll de gerriteerde jongen\\
    the irritated boy\\
    \glt `the irritated boy'} %
  \ex[\#]{\gll de gerriteerde fouten\\
    the irritated mistakes\\
    \glt `the mistakes that were irritated', not `the mistakes that caused
    irritation'}
\end{xlist}
\z
%
But here the semantic explanation is not available: the subject of a verb like
\textit{bevallen} `please\slash suit' is not a Theme\slash Patient, but rather a
Stimulus or equivalent. And \citet[144]{zaenen93} notes that ``if there are any
semantic properties that distinguish the two classes of experiencer verbs under
consideration, they are not the same as the ones distinguishing the two classes
of intransitives''.

In fact, once again the solution is to look at intrinsic assignment of features
at \astruc. The subjects of verbs like \textit{bevallen} do not, in
\citegen[149]{zaenen93} view, possess any proto-agent or proto-patient
entailments; in the event of a tie, \citet[150]{zaenen93} assumes that the
argument is assigned $[-r]$, and so these arguments are treated as being
patientlike. We now have an explanation for the shared unaccusative\slash
unergative split across intransitives and transitives. Just as with
resultatives, the presence of a $[-r]$ argument is the significant factor:
verbs in which the intrinsically $[-r]$-marked argument becomes subject take the
auxiliary \textit{zijn} (otherwise verbs take \textit{hebben}), and the head
noun of the pre-nominal participle corresponds to the $[-r]$ argument -- this
makes such participial uses simply impossible for unergative intransitives,
which have no $[-r]$ argument, and means that the head noun corresponds to the
``logical object'' of transitives.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Double object constructions}\label{sec:argstr:double-object}

The world's languages are divided in how they treat ditransitive predicates. For
some, both objects of a ditransitive are treated equally: for example, either
can be promoted to subject by passivisation, flagged by object marking on the
verb, etc. As mentioned above, these languages are called symmetrical object
languages. Other languages, called asymmetrical object languages, exhibit strong
differences between ``primary'' and ``secondary'' objects, whereby only one
object is eligible for promotion by passivisation, flagging by object marking on
the verb, etc. This distinction was first drawn as a result of work on the Bantu
languages \citep[e.g.][]{Gary:UG,Kisseberth:Chimwini,Baker1988}, where the
divide is particularly clear: since these languages have a productive process of
applicativisation, ditransitive predicates are very frequent, and a number of
grammatical features are sensitive to objecthood.

To illustrate the contrast between symmetrical and asymmetrical object
languages, we consider two languages from the Bantu family: Kichaga and
Chiche\^{w}a. Kichaga is a symmetrical object language, and so either of the
post-verbal arguments in the active can be promoted to subject by passivisation \citep[150]{BresMosh90}:

\ea\label{ex:kichaga-passive-facts}
\ea\label{kichagaappl} {
  \gll N-\H{a}-\H{\i}-ly\`{i}-\'{i}-\`{a} \`{m}-k\`{a} k-\'{e}ly\`{a} \\
  \textsc{foc}-1\textsc{s}-\PRS-eat-\APPL-\textsc{fv} 1-wife 7-food\\
  \glt `He is eating food for\slash on his wife.'\\
}

\ex \label{kichagaapplpassivized1} {
  \gll  \`{M}-k\`{a} n-\H{a}-\H{\i}-ly\`{i}-\'{i}-\`{o} k-\'{e}ly\^{a}\\
  1-wife {\textsc{foc}-1\textsc{s}-\PRS-eat-\APPL-\PASS} 7-food \\
  \glt `The wife is being eaten food for\slash on.'\\ (i.e. `The wife is being benefitted\slash adversely affected by someone eating food.')\\
}

\ex \label{kichagaapplpassivized2}
\gll K-\'{e}ly\`{a} k-\H{\i}-ly\`{i}-\'{i}-\`{o} \`{m}-k\`{a}\\
7-food {7\textsc{s}-\PRS-eat-\APPL-\PASS} 1-wife\\
\glt `The food is being eaten for\slash on the wife.'%
\z
\z
%
Chiche\^{w}a, on the other hand, is an asymmetrical object language. Here, only
the immediately post-verbal argument in the active can be promoted to subject in
the passive \citep[248]{Baker1988}:

\ea\label{ex:chichewa-passive-facts}
\ea[]{
  \gll Kalulu a-na-gul-ir-a mbidzi nsapato.\\
  hare \textsc{s}-\PST-buy-\APPL-\textsc{asp} zebras shoes\\
  \glt `The hare bought shoes for the zebras.'\label{ex:chichewa-applicative-active}}

\ex[]{
  \gll Mbidzi zi-na-gul-ir-idw-a nsapato  ( ndi kalulu ).\\
  zebras \textsc{s}-\PST-buy-\APPL-\PASS-\textsc{asp} shoes {} by hare\\
  \glt `The zebras were bought shoes (by the hare).'\label{ex:chichewa-applicative-good-passive}}

\ex[*]{
  \gll Nsapato zi-na-gul-ir-idw-a mbidzi ( ndi kalulu ).\\
  shoes \textsc{s}-\PST-buy-\APPL-\PASS-\textsc{asp} zebras {} by hare\\
  \glt `Shoes were bought for the zebras (by the hare).'\label{ex:chichewa-applicative-bad-passive}}
%
\z
\z

There are a number of other properties which correlate with the passivisation
facts \citep[150--153]{BresMosh90}. Either or both post-verbal arguments in
Kichaga can be omitted if they are encoded on the verb by an object marker, for
instance, while in Chiche\^{w}a, only the immediately post-verbal Beneficiary
argument can be encoded\slash omitted this way; Kichaga allows unspecified
object deletion of the Patient in a ditransitive where Chiche\^{w}a does not;
Kichaga allows the Patient argument to be eliminated by reciprocal marking on
the verb in the presence of any applied object, while this is not the case in
Chiche\^{w}a; and all of these properties can interact in different ways.

These patterns receive an elegant explanation in Classical LMT, by way of the
\fm{Asymmetrical Object Parameter} (AOP;
\citealp[172]{AlsinaMchombo1990,BresMosh90}). This is a well-formedness
constraint on \astruc{}s, parametrised so that some languages apply it (i.e.
asymmetrical object languages) and others do not (i.e. symmetrical object
languages).

\ea\label{aop}\textit{Asymmetrical Object Parameter}\\
\begin{tabular}[t]{lll}
  *\maplink{$\theta$}{$[-r]$} & \dots & \maplink{$\theta$}{$[-r]$} \\

\end{tabular}
\z
%
The AOP prohibits the presence of two intrinsically classified $[-r]$ arguments
in the same \astruc: when it is in force, secondary patientlike arguments are
assigned $[+o]$ by the intrinsic linking principles introduced in
Section~\ref{sec:argstr:lmt-initial}; when it is not, we permit multiple patientlike
arguments to be assigned $[-r]$ instead. Let us consider how this can explain
the passivisation facts shown in (\ref{ex:kichaga-passive-facts}) and
(\ref{ex:chichewa-passive-facts}).

Chiche\^{w}a is an asymmetrical object language, so the AOP is active. The
a-struc\-ture for an applicative verb like we see in
(\ref{ex:chichewa-applicative-active}) is therefore as follows:

\ea\label{ex:chichewa-applicative-mapping}
\begin{tabular}[t]{lrcccl}
  \textit{gulira} `buy-for' &$\langle$&Agent&Beneficiary&Theme& $\rangle$\\
  &&\maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}&\maplink{$[+o]$}{\OBJTHETA}
\end{tabular}
\z
%
Just as with the English ditransitive above, we interpret the Beneficiary as
patientlike, and so assign it the intrinsic feature $[-r]$. By the AOP, the
second patientlike argument cannot also be marked $[-r]$, so it is instead
classified as $[+o]$. This leads to the (correct) mapping shown in
(\ref{ex:chichewa-applicative-mapping}).

In the passive, only the Beneficiary is eligible for promotion to \SUBJ when the
Agent is suppressed, since the $[+o]$ Theme is featurally incompatible. This
explains the contrast between (\ref{ex:chichewa-applicative-good-passive}) and
(\ref{ex:chichewa-applicative-bad-passive}).

\ea
\begin{tabular}[t]{lrcccl}
  \textit{guliridwa} `buy-for$_{\textsc{passive}}$' &$\langle$&Agent&Beneficiary&Theme& $\rangle$\\
                            &&\maplink{$[-o]$}{$\varnothing$}&\maplink{$[-r]$}{\SUBJ}&\maplink{$[+o]$}{\OBJTHETA}\\
\end{tabular}
\z


Now consider Kichaga. Since it is a symmetrical object language, we are free to
ignore the AOP ban on having two intrinsically $[-r]$-marked arguments. However,
if we do, then we run into trouble in the active:

\ea
\begin{tabular}[t]{lrcccl}
  \textit{ly\`{i}\'{i}\`{a}} `eat-for' &$\langle$&Agent&Beneficiary&Patient& $\rangle$\\
  &&\maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}&\maplink{$[-r]$}{*}
\end{tabular}
\z
%
Since the Agent will be mapped to \SUBJ, we are left with only one remaining
$[-r]$ GF to share between two arguments. So here Kichaga must take the same
option as Chiche\^{w}a of assigning the non-Beneficiary argument $[+o]$ instead:

\ea
\begin{tabular}[t]{lrcccl}
  \textit{ly\`{i}\'{i}\`{a}} `eat-for' &$\langle$&Agent&Beneficiary&Patient& $\rangle$\\
  &&\maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}&\maplink{$[+o]$}{\OBJTHETA}
\end{tabular}
\z

However, in the passive, things are different. Now that the Agent is not mapped
to any GF, there are still two $[-r]$ GFs available. This means the unrestricted
intrinsic mapping of two arguments to $[-r]$ is possible, and will in fact lead
to two possible final mappings:

\ea
\begin{tabular}[t]{lrcccl}
  \textit{ly\`{i}\'{i}\`{o}} `eat-for$_{\textsc{passive}}$' &$\langle$&Agent&Beneficiary&Patient& $\rangle$\\
  &&\maplink{$[-o]$}{$\varnothing$}&\maplink{$[-r]$}{\SUBJ/\OBJ}&\maplink{$[-r]$}{\OBJ/\SUBJ}
\end{tabular}
\z
%
This is exactly the right prediction, since both (\ref{kichagaapplpassivized1}) and (\ref{kichagaapplpassivized2}) are grammatical.

The other properties can also be made to follow from the possibility of having
multiple $[-r]$ arguments or not. Recall that the argument structure operation
of suppression is limited to unmarked arguments (those that possess
negatively-valued intrinsic features) -- it then follows that e.g. unspecified
object deletion applies more freely in symmetrical object languages, which can
have more arguments with negatively-valued features than asymmetrical object
languages.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Complex predicates}\label{sec:argstr:complex-preds}

Complex predicates are predicates which syntactically head single clauses, but
whose meanings incorporate multiple semantic heads and which therefore have
complex argument structures. They have been at the centre of LFG work on
argument structure and mapping theory since the earliest days, and have
consistently drawn a great deal of attention in the literature (e.g.
\citealp{Ishikawa1985,Alsina1992,alsina1996the-role,Butt1995,Butt2014,MohananT1994,Matsumoto1992,Matsumoto1996,AndrewsManning1999,Lowe2015,Lovestrand2020},
among many, many others; see also \citealt[351--352]{DLM:LFG} for an overview of
the range of cross-linguistic work on complex predicates carried out in LFG).%
%
\footnote{There has also been extensive work on computational grammars for LFG
  that can handle complex predicates, with a particular focus on Hindi-Urdu: see
  \citet{buttetal03,urdubigram2012,buttking07,
    boegeletal09-urdugram,sulger2012}.

  Another strand of research worth highlighting studies the consequences of
  complex predicates for the syntax-semantics interface: see
  \citet{dal:etal:93,kaplanwedekind93,AndrewsManning1999,
    Andrews2007,HomolaColer2013,Lowe15}.}
%
As one might expect, therefore, this work has also led to various innovations
and extensions of Classical LMT. In this section, we discuss two of these: the
idea that one \astruc{} can be embedded inside another, with appropriate fusion
of overlapping arguments, and the claim that this \astruc{} composition can take
place in the syntax proper, not just in the lexicon, thus putting paid to the
``lexical'' aspect of Lexical Mapping Theory.%

The first of these points can be seen by considering causatives in Chiche\^{w}a
\citep{Alsina1992}. Verbs containing the causative suffix \textit{-\'its} add an
additional Causer argument which, in the active, surfaces as the subject, with
the previous subject being demoted, either to object or oblique status \citep[518]{Alsina1992}:

\ea \label{causeeobject}
\gll N\v{u}ngu i-na-ph\'{i}k-\'{i}ts-a kadzidzi ma\^{u}ngu.\\
 {9.porcupine} {9\textsc{s}-\PST-cook-\CAUS-\textsc{fv}} {1a.owl} {6.pumpkins}\\
\glt `The porcupine made the owl cook the pumpkins.'
\z

\ea\label{causeekwa}
\gll N\v{u}ngu i-na-ph\'{i}k-\'{i}ts-a ma\^{u}ngu ( kw\'{a} k\'{a}dz\={\i}dzi ).\\
9.porcupine 9\textsc{s}-\PST-cook-\CAUS-\textsc{fv} 6.pumpkins {} to 1a.owl\\
\glt `The porcupine had the pumpkins cooked by the owl.'
\z%
%
Now, we might imagine that such causative forms have a simple \astruc,
containing three argument positions for the Causer, Causee, and original Patient
(here \textit{ma\^ungu}, `pumpkins'). Instead, \citet[521]{Alsina1992} suggests
they have a complex argument structure, formed by embedding the base verb's
\astruc\ into the \astruc\ of the \textsc{cause} predicate, whose Patient is
then merged with one of the arguments of the base predicate:%
%

\ea \label{ex:alsinacausative}
\textsc{cause} $\langle$
\begin{tikzsentence}
  \node (Example-87) {%
    Agent\quad Patient\quad
    $\underbrace{\textsc{pred}\ \langle\dots \theta\dots}_{\textnormal{\normalsize caused event}}\rangle\ \ \rangle$
  };
\draw (Example-87.141) |- ++ (north:1.5ex) -| (Example-87.20);
% \connectabove{schematic-pt}{theta}{1.5}
\end{tikzsentence}
\z %
Where the base predicate has more than one argument, this means there are
multiple possibilities for this \fm{argument fusion}: for instance, the
causative's Patient argument may fuse with either the Agent or Patient of
\textit{ph\={\i}ka} `cook'. \citet[523--524]{Alsina1992} claims that this is
precisely the difference between the two realisations in (\ref{causeeobject})
and (\ref{causeekwa}). In (\ref{causeeobject}), the causative Patient is
combined with the embedded verb's Agent, meaning the Causer's goal was to make
the owl carry out the cooking; this sentence, but not (\ref{causeekwa}), is
therefore a possible answer to the question ``What did the porcupine do to the
owl?''. In (\ref{causeekwa}), however, the causative Patient is fused with the
embedded verb's Patient, meaning the Causer merely intended for the pumpkins to
get cooked, but did not especially care whether the owl did it; this sentence,
but not (\ref{causeeobject}), is therefore a possible answer to the question
``What did the porcupine do to the pumpkins?''.

The fact that an argument of the base predicate is the Patient of the causative
morpheme itself has a number of effects. For instance, although the verb
\textit{ph\={\i}ka} `cook' normally allows deletion of its object, in its
causative form this is not possible, showing that in this respect the object
behaves like an argument of the causative morpheme, rather than of the base
predicate \citep[524--525]{Alsina1992}:

\ea
\gll Kadz\={\i}dzi a-na-ph\H{\i}k-a ( {ma\^{u}ngu )}.\\
1a.owl 1\textsc{s}-\PST-cook-\textsc{fv} {} 6.pumpkins\\
\glt `The owl cooked (the pumpkins).'
\z

\ea
\gll N\v{u}ngu i-na-ph\'{i}k-\^{i}ts-a *( {ma\^{u}ngu )} ( kw\'{a} k\'{a}dz\={\i}dzi ). \\
9.porcupine 9\textsc{s}-\PST-cook-\CAUS-\textsc{fv} {} 6.pumpkins {} to
1a.owl \\
\glt `The porcupine had the pumpkins\slash something cooked (by the owl).'
\z
%

At the same time, the fused argument is also sensitive to its thematic role
within the embedded predicate -- for example, if it is an Agent in the base
predicate it cannot be extracted (e.g. by relativisation), whereas if it is a
Patient then it can \citep[529--530]{Alsina1992}. This mixed behaviour motivates
the idea that two argument positions are fused in the \astruc\ of these complex
predicates.

The assumption of argument fusion also allows a straightforward Classical LMT
account of the mapping possibilities open to causatives in Chiche\^{w}a. The
alternation between (\ref{causeeobject}) and (\ref{causeekwa}), for example,
follows naturally if we assume that when two arguments fuse it is only the
higher one which receives its intrinsic feature assignment:%
%
\footnote{We diverge somewhat from \citegen{Alsina1992} proposal here -- albeit
  only in detail and not in spirit -- in order to harmonise with the approach to
  mapping we introduced earlier.}
%
\ea
\ea \textit{phik\={\i}tsa} `cause to cook'\bigskip\\
    \begin{tabular}[t]{@{}rccrccll@{}}
    $\langle$ & Agent & \ASNode{AS-Example90a-pt}{Patient} & $\langle$
    & \ASNode{AS-Example90a-ag}{Agent} & Patient  &   $\rangle$  & $\rangle$\\
    & \maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}&&&\maplink{$[+o]$}{\OBJTHETA}
    \end{tabular}
\begin{tikzpicture}[remember picture, overlay] 
\connectabove{AS-Example90a-pt}{AS-Example90a-ag}{1.5}
\end{tikzpicture}
\ex \textit{phik\={\i}tsa} `cause to cook'\bigskip\\
    \begin{tabular}[t]{@{}rccrccll@{}}
    $\langle$ & Agent & \ASNode{AS-Example-90b-pt-caus}{Patient} & $\langle$&  Agent
     & \ASNode{AS-Example-90b-pt-cook}{Patient}  &  $\rangle$ & $\rangle$\\
     &\maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}&&\maplink{$[-o]$}{\OBLTHETA}
    \end{tabular}
\begin{tikzpicture}[remember picture, overlay] 
 \connectabove{AS-Example-90b-pt-caus}{AS-Example-90b-pt-cook}{1.5}
\end{tikzpicture}
\z
\z
%
When the causative Patient is fused with the embedded Agent, the embedded Patient
is marked $[+o]$ as a secondary patientlike argument (the higher Patient taking
priority owing to its ranking in the \astruc). When it is fused with the
embedded Patient instead, the embedded Agent now receives a $[-o]$
specification, but since the higher Agent is leftmost in the \astruc, it will
map to \SUBJ, leaving this lower Agent to map to \OBLTHETA instead.

We can also see why the causatives of intransitives do not exhibit this same
alternation -- their Causee can only surface as an \OBJ, never as an \OBLTHETA:

\ea
\gll Chatsal\v{\i}ra a-ku-n\'{a}m-\'{i}ts-\'{a} ( {*} kw\'{a} ) mw\H{a}ina.\\
1.Chatsalira  1\textsc{s}-\PRS-lie-\CAUS-\textsc{fv} {} {} to {} 1.child\\
\glt `Chatsalira is making the child  tell lies.'%
\z
%
This follows naturally from the argument structure facts: since the embedded
predicate only has a single argument, that will necessarily be the argument that
fuses with the causative Patient, and so it is mapped to \OBJ, not to \OBLTHETA:

\ea \textit{nam\v{\i}tsa} `cause to lie'\bigskip\\
    \begin{tabular}[t]{@{}rccrcll@{}}
     $\langle$ & Agent & \ASNode{AS-Ex92-patient}{Patient} &   $\langle$&  \ASNode{AS-Ex92-agent}{Agent}  &  $\rangle$  & $\rangle$\\
     &\maplink{$[-o]$}{\SUBJ}&\maplink{$[-r]$}{\OBJ}
    \end{tabular}
\begin{tikzpicture}[remember picture, overlay]
 \connectabove{AS-Ex92-patient}{AS-Ex92-agent}{1.5}
\end{tikzpicture}
\z

Chiche\^{w}a forms causatives morphologically, and so the processes of \astruc{}
composition and argument fusion can be thought of as taking place in the
lexicon. However, some complex predicates are made up of multiple words, and so
their argument structures must be built in the syntax rather than in the
lexicon. \citet{Butt1995}, studying Hindi-Urdu permissive and aspectual
constructions, and \citet{alsina1996the-role}, studying Romance causatives, were
among the first to make this observation. We will illustrate the phenomenon with
Hindi-Urdu data.

In Hindi-Urdu, complex predicates can be formed from a combination of a main
verb and a light verb. In the case of so-called permissive complex predicates,
the light verb in question is \textit{de} `let', homophonous with the lexical
verb meaning `give' \citep[35]{Butt1995}. As with the causative morpheme, the
light verb contributes its own arguments, which are added to and overlap with
the arguments of the main predicate. For example, in
(\ref{urdupermissiveinitial}), \textit{saddaf=ko} is at once the ``lettee''
argument of the light verb \textit{diyaa} and the ``maker'' argument of
\textit{banaane} `make' (other arguments belong to only one verb:
\textit{anjum=ne} is only an argument of \textit{diyaa} -- she is the the one
giving permission -- and \textit{haar} `necklace' is only an argument of
\textit{banaane} -- it is the thing being made).

\ea\label{urdupermissiveinitial}
\gll anjum=ne saddaf=ko haar banaa-ne di-yaa.\\
    % a b c\\
     Anjum.\textsc{f}=\ERG{} Saddaf.\textsc{f}=\DAT{} necklace.\textsc{m}.\NOM{} make-\INF.\OBL{} give-\textsc{perf}.\textsc{m}.\SG{}
     \\
\glt `Anjum let Saddaf make a necklace.'
\z

The light verb and main predicate do not have to be adjacent or form a
constituent at \cstruc, so there is no sense in which they can be analysed as a
single, morphologically complex word \citep[46]{Butt1995}:

\ea\label{ex:urdu-scrambling}
\ea anjum=ne saddaf=ko haar [\textbf{banaa-ne di-yaa}].
\ex anjum=ne \textbf{di-yaa} saddaf=ko [haar \textbf{banaa-ne}].
\ex anjum=ne [haar \textbf{banaa-ne}] saddaf=ko \textbf{di-yaa}.
\z
\z
%
Nevertheless, these sentences do not involve clausal embedding: with respect to
agreement, anaphora, and control, they behave monoclausally (see
\citealt[36--43]{Butt1995} for detailed evidence of this). That is, they have a
flat \fstruc, shown in (\ref{ex:urdu-fstruc}):%
%
\footnote{The question of how the composite \PRED value emerges here is an
  unanswered one -- see \citet[sec.~2]{Lowe2015} for a sceptical review,
  and see \citet[sec. 4]{asudeh-rafieerad-lfg23} for a technical solution.
  }
%

\ea\label{ex:urdu-fstruc}
\avm[style=fstr]{%
  [pred &  `let-make$\langle$\SUBJ,\OBJ,\OBJROLE{goal}$\rangle$\\
  subj & [pred &  `Anjum']\\
  \OBJROLE{goal} & [pred &  `Saddaf']\\
  obj & [pred &  `necklace']
  ]
}
\z
%
This means the complex predicate must also have a single, composite \astruc:


\ea \resizebox{\linewidth}{!}{%
\textit{de} `let\slash give'
    \begin{tabular}[t]{@{}rcclrccll@{}}
      $\langle$ & Agent & \ASNode{AS-Ex96-caus-goal}{Goal}   & \textit{banaa} `make' & $\langle$& \ASNode{AS-Ex96-make-agent}{Agent} & Theme & $\rangle$ & $\rangle$\\
     &\maplink{$[-o]$}{\SUBJ}&\maplink{$[+o]$}{\OBJROLE{goal}}& &&&\maplink{$[-r]$}{\OBJ}
    \end{tabular}
\begin{tikzpicture}[remember picture, overlay]
 \connectabove{AS-Ex96-caus-goal}{AS-Ex96-make-agent}{1.5}
\end{tikzpicture}
}
\z
%
But this \astruc\ cannot be the property of any one word in the lexicon, since
it combines information from two words, and the light verb can freely combine
with various predicates. What is more, complex predicates can be recursively
embedded -- \citet{buttetal09} give an example involving four levels of
embedding, for instance:

\ea
\gll taaraa-ne amu-ko (bacce-se) haathii pinc kar-vaa le-ne dii-yaa.\\
Tara-\ERG{} Amu-\DAT{} child.\OBL-\INS{} elephant.\textsc{m}.\SG.\NOM{} pinch do-\CAUS{}
take-\INF.\OBL{} give-\PRF.\textsc{m}.\SG\\
\glt `Tara let Amu have the elephant pinched (by the child) (completely).'
\z
%
The core meaning here is the noun-verb complex predicate made up of
\textit{pinc} `pinch' and \textit{kar} `do'. This is then embedded under a
causative predicate, which is hosted morphologically on this same light verb.
Then we have a ``completive'' light verb \textit{le} (with the lexical meaning
`take'). Finally, this whole complex is embedded under the permissive light verb
\textit{de}, which we saw above.

The conclusion such data must lead us to is that complex predicate formation is
a productive, syntactic process, which means that we need to be able to combine
\astruc{}s on-line, outside of the lexicon. Apart from anything else, this means
that the name ``Lexical Mapping Theory'' is a misnomer, since the theory must
not apply only to individual words, but also to complex predicate-argument
structures built up syntactically.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Kibort MT: incorporating morphosemantic
  alternations}\label{sec:argstr:morphosemantic-alternations}

We've now seen a sampling of the successes of and challenges for Classical LMT.
In this section, we turn to a rather different view of LMT, that developed by
Kibort over a series of papers
\citep{Kibort2001,Kibort2001,Kibort2007,Kibort:08,Kibort2009,kibort13,kibort14,KM15},
which purports to improve on Classical LMT in a number of respects, not least of
which being its ability to handle morphosemantic alternations. We will refer to
this theory as \fm{Kibort MT}.

As we saw in Section~\ref{sec:argstr:lmt-initial}, the dative shift alternation poses a
challenge for Classical LMT, in that the theory must assume two distinct initial
assignments of features to arguments in order to be able to derive the two
alternants. Other morphosemantic alternations are even more challenging.
Consider again the \textit{spray\slash load} alternation
\citep[50--51]{levin93}, illustrated in (\ref{ex:spray-load}):

\ea\label{ex:spray-load}
\begin{xlist}
  \ex Adam sprayed the paint on the wall.\label{ex:spray-load-theme-obj}
  \ex Adam sprayed the wall with the paint.\label{ex:spray-load-goal-obj}
\end{xlist}
\z
%
This is morphosemantic insofar as the entailments of the alternants differ: in
each case, the participant corresponding to the \OBJ is completely affected --
i.e. in (\ref{ex:spray-load-theme-obj}) the paint is fully used up, while in
(\ref{ex:spray-load-goal-obj}) the wall is totally covered. Once again, both
alternants involve the same thematic roles, and so the basic Classical LMT
\astruc\ will be the same for both:

\ea
\begin{tabular}[t]{lrcccl}
  \textit{spray}&$\langle$&Agent&Goal&Theme&$\rangle$
\end{tabular}
\z


We would expect the Theme, being patientlike, to be assigned $[-r]$, and the
other arguments to receive the default $[-o]$ assignment; this correctly
produces the alternant in (\ref{ex:spray-load-theme-obj}), where the Theme
surfaces as \OBJ, and the Goal as an \OBLTHETA:

\ea
\begin{tabular}[t]{lrcccl}
  \textit{spray} &$\langle$&Agent&Goal&Theme&$\rangle$\\
  & &\maplink{$[-o]$}{\SUBJ}&\maplink{$[-o]$}{\OBLTHETA}&\maplink{$[-r]$}{\OBJ}
\end{tabular}
\z
%
Producing the other alternant, in (\ref{ex:spray-load-goal-obj}), is much more
difficult, however. Compared to (\ref{ex:spray-load-theme-obj}), we need the
Goal and Theme to switch GFs: the former now surfaces as an \OBJ, and the latter
as an \OBLTHETA. We could try the same trick as we did for ditransitive
\textit{give}, and say that the Goal argument counts as patientlike: this will
allow us to classify it as $[-r]$, so that it can map to \OBJ. But now the Theme
will receive a $[+o]$ assignment as a secondary patientlike argument, which is
incompatible with the $[-o]$ GF \OBLTHETA. Indeed, patientlike arguments can
only be classified as $[-r]$ or $[+o]$ by the intrinsic assignments in
(\ref{ex:new-intrinsic}), which is precisely the opposite of what is needed to
be compatible with the $[+r, -o]$ specification of \OBLTHETA.

In Kibort's view, the problem arises because Classical LMT conflates syntactic
arguments and semantic participants, representing both simultaneously in the
list of arguments-\textit{cum}-thematic roles. She proposes therefore to expand
the domain of \astruc\ and mapping theory to include not only
\fm{argument-func\-tion mapping}, i.e. what we have been considering as the domain
of mapping theory up to now, but also \fm{argument-participant mapping}.%
%
\footnote{In other works by Kibort, these are referred to as
  ``argument-\textbf{to}-function\slash participant mapping'', but since the
  connections are intended to be bidirectional, we omit the preposition here to
  minimise the procedural implications.}
%
This is illustrated in Figure~\ref{fig:exploded-astruc}, representing the typical active voice realisation of the Polish double object verb \textit{da\'{c}}
`give' \citep[cf.][265]{kibort14}.%
\footnote{As \citet[252]{Kibort2007} points out, separating argument positions from semantic participants in fact goes back to early LFG work (such as \citealt{bresnan1982the-passive}), and has been argued for by others such as \citet[1]{Grimshaw1988}, \citet{Mohanan1990}, \citeauthor{Ackerman1991} (\citeyear[12]{Ackerman1991}, \citeyear[57ff]{Ackerman1992}), \citet[15ff]{MohananT1994}, \citet{Joshi93}, \citet[37]{alsina1996the-role}, \citet[105]{falk2001lexical}, and \citet[40ff]{AckermanMoore2013}.}

\begin{figure}
\resizebox{\textwidth}{!}{%
  \begin{tabular}[t]{@{}rcccll@{}}
    semantic participants  &    Agent &   Theme   &  Recipient   &   \textsc{semantic valency} \\
                           &   $|$   &   $|$  &   $|$   &  \\
    arguments of the predicate  &   \llap{$\langle$} arg$_1$  &   \ensuremath{\textnormal{arg}_2}   &  \ensuremath{\textnormal{arg}_3} \rlap{$\rangle$} &  \textsc{lexical valency}\\
                            &   $|$   &   $|$  &   $|$   &   \\
    grammatical functions   &  \SUBJ  &  \OBJ   &  \OBJTHETA  & \textsc{functional subcategorisation} \\ %
  \end{tabular}}
\caption{The separation of levels in Kibort MT\label{fig:exploded-astruc}}
\end{figure}
%
Before providing the Kibort MT solution to the \textit{spray\slash load} puzzle,
we first introduce the theory in more detail.

Kibort retains the Classical LMT mapping features $[\pm r]$ and $[\pm o]$, but,
in keeping with the separation of syntax and semantics shown in
Figure~\ref{fig:exploded-astruc}, she reinterprets them in purely syntactic
terms, according to two traditional classifications of verbal dependents
\citep[266]{kibort14}:%
\footnote{At least two other LFG linguists have proposed LMT feature sets which
  make no reference to semantic\slash thematic restrictions:
  \citet{alsina1996the-role} and \citet{Hemmings2012}.}
%

\begin{exe}\ex\label{featuredefinitions}
\resizebox{.92\textwidth}{!}{
\begin{tabular}[t]{lll}
  $[-o]$ & non-complements    & (the ``external'' argument and oblique arguments) \\
  $[+o]$ & complements        & (``internal arguments'' of the predicate) \\
  $[-r]$ & core arguments     & (subject and object only)  \\
  $[+r]$ & non-core arguments & (all arguments except subject and object)  \\
\end{tabular}
}~
\end{exe}
%
These features are associated with positions in a universally available lexical
valency frame, from which predicates select a subset of argument positions:

\ea\label{universalsubcatframe}
\ensuremath{%
\begin{array}[t]{cccccccc}
\langle & \textnormal{arg}_1 & ~~\textnormal{arg}_2~ & ~~\textnormal{arg}_3~ & ~\dots~ & ~~\textnormal{arg}_4~ & ~\dots~ & \rangle\\
				& [-o]/[-r]    & [-r]         & [+o]    & [+o]      & [-o]     & [-o]   &  \\
\end{array}
}
\z
%
The ordering and feature assignment in (\ref{universalsubcatframe}) is based on
the standard LFG Functional Hierarchy, repeated in
(\ref{ex:functional-hierarchy-repeat}):

\begin{exe}
\ex \label{ex:functional-hierarchy-repeat}\textit{The Functional Hierarchy:}\\
$\SUBJ > \OBJ > \OBJTHETA\ (> \XCOMP, \COMP) > \OBLTHETA\ (> \XADJ, \ADJ)$ .
\end{exe}
%
The first position in (\ref{universalsubcatframe}), called mnemonically
arg$_{1}$, corresponds to the canonical subject, and is associated with one of
the two features which describe the \SUBJ function (it is marked $[-o]$ in
unergative predicates, emphasising its non-complement status, and $[-r]$ in
unaccusative ones, emphasising its core status).%
%
\footnote{Although the unergative\slash unaccusative distinction was originally
  applied only to intransitive predicates \citep{Perlmutter1978}, subsequent
  work has extended it to predicates of all valencies: see
  \citet[74--75]{Kibort2004} for discussion, and cf. the Dutch experiencer verbs
  discussed in Section~\ref{sec:argstr:unaccusativity}, which exhibited the same
  syntactic split as intransitive unergatives\slash unaccusatives.}
%
The second position, arg$_{2}$, corresponds to the canonical direct object, and
is marked $[-r]$ (core). The next position, arg$_{3}$, corresponds to the
restricted object, and is marked $[+o]$ (complement). Lastly, arg$_{4}$,
corresponds to a canonical oblique argument, and is marked $[-o]$
(non-complement). Predicates can select any number of arguments from this frame,
but, as indicated, they can only choose one arg$_{1}$ and arg$_{2}$, though they
can select multiple arg$_{3}$s and arg$_{4}$s -- this corresponds to the fact
that a predicate can subcategorise for only a single \SUBJ and \OBJ, whereas
multiple \OBJTHETA{}s and \OBLTHETA{}s are permitted, being individuated by
their subscripts (e.g. \OBJROLE{theme} vs. \OBJROLE{ben}).%
%
\footnote{While these functions are often indexed by thematic roles, this can be
  understood purely for distinctiveness, having no semantic content: instead of
  \OBJROLE{theme} and \OBJROLE{ben} we could use other mnemonic labels such as
  cases (e.g. \OBJROLE{acc} vs. \OBJROLE{dat}, etc.) or preposition names (e.g.
  \OBLROLE{to} vs. \OBLROLE{on}, etc.), or purely arbitrary labels such as
  \OBJROLE{1} and \OBJROLE{2}. Thus, the retention of the GFs \OBJTHETA and
  \OBLTHETA does not diminish the syntactically-motivated characterisation of
  GFs in Kibort MT.}
%

What we have considered as mapping so far in this chapter corresponds to
``argument-function mapping'' in Kibort MT, i.e. the linking of argument
positions and GFs. As in Classical LMT, arguments in Kibort MT are associated
with a feature specification that makes them compatible with two different GFs,
and mapping therefore consists in determining which of the two (if either) will
realise the argument syntactically. Kibort MT diverges from Classical LMT,
however, in only having a single Mapping Principle (\citealp[267]{kibort14}; cf.
\citealt{Her2013}):

\ea\label{ex:kibort-mapping-principle}
\textit{Mapping Principle (Kibort MT):}\\
The ordered arguments are mapped in turn onto the highest (i.e. \emph{least}
marked) compatible grammatical function on the Markedness Hierarchy.
\z
%
This inverts Mapping Principle (b) of Classical LMT, which maps arguments to the
lowest, i.e. \emph{most} marked, compatible GF, and in so doing removes the need
for Mapping Principle (a), along with the Subject Condition, as we shall see.
This is clearly a huge gain in parsimony, though it is not without cost, as we
discuss below.

By way of illustration, consider again the simple transitive (and unergative)
verb \textit{kick}. This has the following Kibort MT \astruc:

\ea
\begin{tabular}[t]{lrccl}
  \textit{kick} & $\langle$&arg$_{1}$&arg$_{2}$&$\rangle$\\
  && $[-o]$ & $[-r]$
\end{tabular}
\z
%
By the Mapping Principle, we first map the highest argument, arg$_{1}$, onto the
highest compatible GF: in this case, the highest $[-o]$ GF is \SUBJ, so this is
what we choose. Next, arg$_{2}$ is mapped onto the highest $[-r]$ GF available:
since \SUBJ is already taken, this is \OBJ.%
%
\footnote{Function-Argument Biuniqueness still applies in Kibort MT, although
  it may not be necessary to stipulate it as a separate principle -- see
  fn.~\ref{fn:consistency}.}
%
Note that despite the procedural talk here and in the Mapping Principle itself
(arguments are mapped ``in turn''), this process is intended to be understood
declaratively. It can be seen as optimising the alignment between two
hierarchies: are the highest arguments linked to the highest GFs? This can then
be solved using various constraint-based tools such as those of Optimality
Theory (\citealp{PrinceSmolensky1993,PrinceSmolensky2004}; cf. also
\citealt{Asudeh01} for an application of OT to mapping in an LFG context).

Morphosyntactic argument alternations interfere with the default
argument-function mapping. As in Classical LMT, this is achieved monotonically,
by further specifying the mapping possibility of an argument. However, Kibort MT
goes even further in this respect, eschewing the use of suppression altogether,
and thus sidestepping the issues mentioned in fn.~\ref{fn:suppression}. For
instance, \citet[170]{Kibort2001} treats passivisation as a further
specification of arg$_{1}$ as $[+r]$, illustrated in (\ref{kick-passive-kibort})
for passive \textit{kicked} (cf. (\ref{ex:kick-astruc-passive}) above):

\begin{exe}
\ex \label{kick-passive-kibort}
\ensuremath{%
\begin{array}[t]{ccccc}
  \textit{kicked}_\textsc{passive} & \langle & \textnormal{arg}_1 & \ensuremath{\textnormal{arg}_2} & \rangle\\
                                   &  & [-o]   & [-r]   &   \\
                                   &  & [+r]   &        &   \\
    % &  & \OBLTHETA  &  \SUBJ  &  \\
\end{array}
}
\end{exe}
%
The argument which by default would map to \SUBJ is instead fully specified as
an \OBLTHETA, and, as a result, the \ensuremath{\textnormal{arg}_2}, if there is
one, becomes the \SUBJ. Note that this gives the correct result for the English
long passive, where the Agent is expressed as an oblique \textit{by}-phrase, but
in the short passive the Agent is not expressed grammatically at all.
\citet[e.g.][29]{Kibort2004} refers to such obliques as ``optional'', but it is
not clear what determines this -- it cannot be the case that \OBLTHETA{}s are
always optional, for instance, since there are certainly cases of obligatory
obliques, as in \textit{I gave the book *(to my friend)}.

In general, morphosyntactic operations are assumed to involve making arguments
more marked, by adding additional $+$-valued specifications:

\begin{exe}
    \ex \label{morphosyntactic-operations}
    \begin{xlist}
    \ex adding the $[+r]$ specification to a $[-o]$ argument \\(e.g. passivisation)%
    \ex adding the $[+r]$ specification to a $[+o]$ argument \\ (e.g. secondary
    object preservation -- \citealt[268]{Kibort2007})%
    \ex adding the $[+o]$ specification to a $[-r]$ argument \\(e.g. locative
    inversion -- \citealt[364--367]{Kibort2004})%
    %\citealt[267]{Kibort2007}
    % (e.g. object preservation: \citealt[368]{Kibort2004})
  \end{xlist}
\end{exe}

% Two of these three involve adding $[+r]$ to an argument, which means marking it as non-core -- this corresponds to the many ``demotional'' processes found in the world's languages.


One thing to note about argument-function mapping in Kibort MT is that the
Subject Condition of Classical LMT is absent. The motivation for this is that
genuinely subjectless predicates are quite common in the world's languages (see
\citealt{Kibort2006} and \citealt{lowe-etal2021} for discussion). For instance,
Polish intransitives can be passivised, resulting in a subjectless sentence
\citep[304--307]{Kibort2006}:

\begin{exe}
  \ex \label{bylosprzatane-intrans}
  \gll By{\l}o codziennie sprztane (przez firm).\\
  was.\textsc{3sg.n} every-day clean.\textsc{part.sg.n} (by company)\\
  \glt `There was cleaning every day (by a company).'
\end{exe}
%
This follows quite naturally in Kibort MT, where the verb will have the
following \astruc, resulting in the first and only argument being mapped to
\OBLTHETA, rather than \SUBJ:

\begin{exe}
  \ex \label{polish-clean-a-struc}%
  \ensuremath{%
    \begin{array}[t]{cccc}
      \textit{sprzta}_{\textsc{passive}} & \langle & \textnormal{arg}_1 & \rangle\\
                                           &  & [-o]    &   \\
                                           &  & [+r]    &   \\
                                           % &  & \OBLTHETA  &  \\
    \end{array}
  }%
\end{exe}
%
The strong cross-linguistic preference for subjects is captured in the Mapping
Principle: since arguments are mapped to the highest available GF on the
Markedness Hierarchy, and since \SUBJ is at the top of that hierarchy, \SUBJ
will always be the most preferred GF, meaning \emph{something} will usually map
to it. But by making this a strong preference rather than a principle of the
grammar, Kibort MT also allows for the possibility of subjectless predicates in
marked circumstances -- such as the passivisation of an intransitive.

One negative side effect of this choice, however, is that Kibort MT apparently
makes the wrong predictions about the passive of double object verbs. As
mentioned above in Section~\ref{sec:argstr:arg-alternations-in-lmt}, when a double
object verb is passivised, and so the primary object is promoted to \SUBJ, it is
apparently \emph{not} the case that the secondary object is promoted to primary
object -- but this is exactly what Kibort MT predicts should happen, since the
$[+o]$-valued arg$_{3}$ of a secondary object argument is compatible with \OBJ,
and \OBJ is less marked than \OBJTHETA (though see \citealt{Kibort:08}).

The Kibort MT approach to argument-function mapping offers a different
perspective from Classical LMT, and perhaps represents an advancement in certain
areas, in particular with respect to theoretical parsimony. However, the real
advantage of the theory is in the fact that argument-\emph{participant} mapping
can interact in interesting ways with argument-function mapping. Let us return
now to the question of the \emph{spray\slash load} alternation. The verb
\textit{spray} in this sense will have the following \astruc\ and
argument-function mappings:

\ea
\ensuremath{%
\begin{array}[t]{cccccc}
   % &  & 1 & 24\rlap{$_\textsc{loc}$} & 24\rlap{$_\textsc{inst}$}  & \\
\textit{spray}   &    \langle  & \textnormal{arg}_1 & \textnormal{arg}_2 & \textnormal{arg}_4  & \rangle \\
	   &    & \maplink{$[-o]$}{\SUBJ}   & \maplink{$[-r]$}{\OBJ}    & \maplink{$[-o]$}{\OBLTHETA}    &
\end{array}
}
\z
%
In fact, these GFs are the same ones which appear in both alternants -- the only
difference is which participants map to which GFs. Because Kibort MT posits a
separate level of semantic participants, the mapping between those participants
and the argument positions -- and so, indirectly, the GFs -- can be allowed to
vary.

\ea\label{ex:spray-a-strucs-with-thematic-roles}
\begin{xlist}
  \ex Adam sprayed the wall with the paint.
  \ex\label{ex:spray-original-alignment}
\ensuremath{%
  \begin{array}[t]{cccccc}
    \textit{spray}   &    \langle  & \maplinkup{arg$_1$}{Agent} & \maplinkup{arg$_2$}{Goal} & \maplinkup{arg$_4$}{Theme}  & \rangle \\
                     &    & \maplink{$[-o]$}{\SUBJ}   & \maplink{$[-r]$}{\OBJ}    & \maplink{$[-o]$}{\OBLTHETA}    &
  \end{array}
}
\end{xlist}
\ex
\begin{xlist}
\ex Adam sprayed the paint on the wall.
\ex\label{ex:spray-realigned}
\begin{tabular}[t]{@{}cccccc@{}}
  & & \ASNode{AS-Ex112b-agent}{\textnormal{Agent}} & \ASNode{AS-Ex112b-theme}{\textnormal{Goal}} & \ASNode{AS-Ex112b-goal}{\textnormal{Theme}}\\
  \\
  \textit{spray}   &    $\langle$  & \ASNode{AS-Ex112b-arg1}{\textnormal{arg}$_1$} & \ASNode{AS-Ex112b-arg2}{\textnormal{arg}$_2$} & \ASNode{AS-Ex112b-arg4}{\textnormal{arg}$_4$} & $\rangle$ \\
   &    & \maplink{$[-o]$}{\SUBJ}   & \maplink{$[-r]$}{\OBJ}    & \maplink{$[-o]$}{\OBLTHETA}    &
\end{tabular}
\begin{tikzpicture}[remember picture, overlay]
\draw (AS-Ex112b-arg1.north) -- (AS-Ex112b-agent.south);
\draw (AS-Ex112b-arg2.north) -- (AS-Ex112b-goal.south);
\draw (AS-Ex112b-arg4.north) -- (AS-Ex112b-theme.south);
\end{tikzpicture}
\end{xlist}
\z
%

Although for a human reader it may be easier to track the re-aligned
participants in diagrams like (\ref{ex:spray-original-alignment}) and
(\ref{ex:spray-realigned}) if they are represented by thematic role labels,
Kibort MT takes the criticisms of thematic roles mentioned in
Section~\ref{sec:argstr:sem-to-syn} to heart, and so they play no role in the theory.
Furthermore, \citet{kibort14} argues that neither Dowty-style proto-roles nor
feature decomposition attempts are adequate either. In the absence of an
adequate and complete representation of lexical knowledge, Kibort MT instead
adopts a very minimal representation of semantic participants. In this system,
semantic participants are labelled by numbers which identify which arg positions
they can map to \citep[275ff.]{kibort14}. For example, the \astruc\ of
\textit{spray} would be augmented as follows:

\ea\label{spray_semantic_valency}
\ensuremath{%
  \begin{tabular}[c]{lrcccl}
    && 1 & 24$_\textsc{th}$ & 24$_\textsc{go}$ \\
    % \\
    \textit{spray}   &    $\langle$  & arg$_{1}$ & arg$_{2}$ & arg$_{4}$  & $\rangle$ \\
    & & $[-o]$ & $[-r]$ & $[-o]$
\end{tabular}
}
\z
%
The first semantic participant is labelled 1 since it can only be linked to the
arg$_{1}$ position, but the other two are labelled 24 since they can be linked
to either the arg$_{2}$ or the arg$_{4}$ position. The subscripts on the
semantic participants are purely for distinctness, to individuate the two
participants with identical labels, and have no semantic content.

Argument-participant mapping has no principles beyond stating that participants with label $n$ can be linked to argument arg$_{n}$; arguments whose labels contain multiple numbers, like the Theme and Goal in (\ref{spray_semantic_valency}), are assumed to bear multiple labels, i.e. each of the Theme and Goal in (\ref{spray_semantic_valency}) simultaneously has the label 2 and the label 4. In cases where multiple mappings are possible, Kibort MT predicts that neither is more basic than the other, since there is no preference ranking encoded in the argument-participant mapping. This is certainly right for the \textit{spray\slash load} alternation, since there does not seem any reason to assume that one alternant is derived from the other or that one is more basic than the other, especially given that this alternation is unmarked in English (i.e. there is no morphological or syntactic marker in either version).%
%
\footnote{It may be possible to argue that one of the variants is more basic on
  non-linguistic grounds, e.g. by reference to the relative prominence of
  cognitive concepts like Figure and Ground (\citealp{talmy78}; see also
  \citealt{schaetzle18} for an implementation of these concepts within LFG's
  mapping theory), but a strength of Kibort~MT is that such a move is not
  \emph{necessary}, even if it may sometimes be independently motivated.}
%

Kibort MT thus draws a clear formal distinction between morphosyntactic
(meaning-preserving) and morphosemantic (meaning-altering) alternations: the
former affect the argument-function mapping, using techniques very similar to
those of Classical LMT; the latter affect the argument-participant mapping,
something made possible by separating out these two levels of representation.

In sum, Kibort MT offers a mapping theory that on the one hand simplifies, and
on the other hand elaborates on Classical LMT. It is simpler in that there is a
universal valency frame, a single Mapping Principle, and no mention of thematic
roles, but it is more complex in that it separates out the notion of argument
from semantic participant. This does, however, offer the possibility of
straightforwardly representing the effects of meaning-altering, morphosemantic
alternations, something that was not always possible in Classical LMT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Formal issues and recent developments}\label{sec:argstr:formal-issues}

Aside from Kibort's focus on expanding the empirical coverage of LMT, another
major thread in contemporary work on argument structure and mapping theory has
been an increased interest in questions of formalisation. In this section, we
address three areas in this vein: the formal status of \astruc, the nature of
mapping, and the integration of mapping theory and compositional semantics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The position and nature of \astruc}\label{sec:argstr:position-of-astruc}

In Kibort MT, Classical LMT, and earlier work, the position of argument
structure in the architecture of the grammar is left vague or unmentioned.
Sometimes, it is (implicitly) assumed to be situated inside \fstruc, as (part
of) the value of \PRED, but otherwise the question does not arise.

\citet[1]{butt1997architecture} are the first to address this formal deficiency
head on, and propose that argument structure forms its own level of
representation, \astruc{}, situated in the LFG projection architecture between
\struc{c} and \struc{f}:

\ea\label{ex:butt-etal-architecture}
\begin{minipage}[c]{0.05\textwidth}
\begin{forest}
[\subnode{v}{V} [cut]]
\end{forest}
\end{minipage}
%
\hspace*{4em}
%
\avm[pic,picname=astr-b,style=fstr]{%
[
\node{astr-1}{rel} &  \node{astr}{\normalfont\rmfamily eat}  \\
agent & \emptybracks\node{agent}{}\\
theme & \emptybracks\node{theme}{}
]
}
%
\hspace*{4em}
%
\avm[pic,picname=fstr-b,style=fstr]{
[
\node{fstr}{pred} & \node{eat}{\normalfont\rmfamily `eat'} \\
subj & \node{subj}{\emptybracks} \\
obj & \node{obj}{\emptybracks}
]
}
%
\hspace*{4em}
%
\begin{minipage}{0.05\textwidth}
\avm[pic,picname=sstr-b]{
\node{s-clause}{}\emptybracks\\
\node{s-arg1}{}\emptybracks\\
\node{s-arg2}{}\emptybracks
}
\end{minipage}
\begin{tikzpicture}[overlay,remember picture]
\node [fit=(astr-b-astr-1) (astr-b-theme), outer sep=2pt] (AS-Ex114-group-1) {};
\draw[-stealth] (v) to[out=east, in=west] node[pos=0.6, above]{$\alpha$} (AS-Ex114-group-1);%
\strucconnectdashed{v}{fstr-b-obj}{0.6}{$\phi=\lambda \circ \alpha $}{-45}{-150}
% \strucconnect{v}{astr-b-astr-1}{0.6}{$\alpha$}{east}{west}

\node [fit=(fstr-b-fstr) (fstr-b-obj) (fstr-b-eat), outer sep=2pt] (AS-Ex114-group-2) {};
\strucconnect{AS-Ex114-group-1.20}{AS-Ex114-group-2.165}{0.5}{$\lambda$}{east}{west}
\strucconnect{astr-b-agent}{fstr-b-subj.183}{0.3}{$\lambda$}{east}{195}
\strucconnect{astr-b-theme}{fstr-b-obj.183}{0.3}{$\lambda$}{east}{195}
%
%
\strucconnect{AS-Ex114-group-2.20}{sstr-b-s-clause}{0.5}{$\sigma$}{east}{west}
\strucconnect{fstr-b-subj}{sstr-b-s-arg1}{0.5}{$\sigma$}{east}{west}
\strucconnect{fstr-b-obj}{sstr-b-s-arg2}{0.5}{$\sigma$}{east}{west}
\end{tikzpicture}
\\\vspace*{6ex}\hfill\citep[1, their ex. (1)]{butt1997architecture}
\z
%
This positioning is motivated by the complex predicate facts discussed in
Section~\ref{sec:argstr:complex-preds}. Since complex \astruc{}s can correspond to
simplex (monoclausal) \fstruc{}s, and since the projection functions, as
functions, can be many-to-one but not one-to-many, \astruc{} must be mapped to
\fstruc{}, and not vice versa. On the other hand, since complex \astruc{}s can
be built from discontinuous pieces in the syntax, and are not necessarily
generated in the lexicon, \astruc{} must be positioned after \cstruc{}, so that
information can be passed from the latter to the former.

One immediate effect of this positioning is to break up the traditional $\phi$
mapping from c- to \fstruc{}: it is now the composition of two functions, the
$\alpha$ function from c- to \astruc{}, and the $\lambda$ function from a- to
\fstruc{}, i.e. $\lambda \circ \alpha$.%
%
\footnote{\citet[1]{butt1997architecture} identify $\phi$ with
  $\alpha \circ \lambda$ (rather than $\lambda \circ \alpha$), but this must be
  an error, since $\alpha$ has to be applied before $\lambda$, given their
  architecture.}
%
Some have seen this as undesirable: for example, \citet{AsudGior12} propose a
change to the architecture (to be discussed shortly), one of the effects of
which is to restore $\phi$ to its atomic status, and they claim this as an
advantage of their proposal \citep[71]{AsudGior12} -- but if this is an
advantage, we do not see how it can be anything other than an aesthetic one.

Unlike in most earlier approaches, for \citet{butt1997architecture}, \astruc s
are not simply lists of arguments, but are instead AVMs. This allows for a
richer internal structure: for example, complex predicates have nested \astruc s
\citep[12]{butt1997architecture}. Each \astruc\ contains a \textsc{rel}
attribute that names the semantic relation it encodes, and attributes labelled
with thematic role names corresponding to argument positions. Nothing further is
said about the value of these attributes, and they are represented as empty AVMs
in \citet{butt1997architecture}. These must be shorthand for more complete
structures, however, since otherwise, under a standard set-theoretic
interpretation of AVMs, all the ``empty'' AVMs would in fact be one and the
same.%
%
\footnote{For discussion of a similar problem, this time with regard to
  \sstruc, see \citet[348--353]{findlay2021}.}
%

\citet{AsudGior12} criticise \citegen{butt1997architecture} architecture and
propose an alternative which has since proven influential. They do so on the
basis of verbs which take optional objects, like \textit{eat} in English:

\ea\label{ex:optional-object-pair}
\ea Donatello ate a pizza earlier.
\ex Donatello ate earlier.
\z
\z
%
Although the Patient argument does not need to be expressed in the syntax, it
must still be present in the \astruc, since it remains part of the core relation
expressed by the verb (eating events involve something being eaten), and must
also be represented at \sstruc, since it is interpreted semantically: the truth
of \textit{Donatello ate} implies the truth of \textit{Donatello ate something}.
This poses a problem for the \citet{butt1997architecture} architecture, since
there is no route through the projection architecture from the \astruc{}
\textsc{patient} to its corresponding \sstruc{} without going via its \fstruc{}
representation% %(because there are no direct relations between different \sstruc{}s)%
, and it appears not to have one:

\ea\label{ex:butt-et-al-architecture-schematic}
\avm[pic,picname=astr-1,style=fstr]{%
[
rel & \node{eat}{\normalfont\rmfamily eat}  \\
agent & \node{agent}{\emptybracks}\\
\node{patient}{patient} & \emptybracks\node{theme}{}
]
}
\hfill
\avm[pic,picname=fstr-1,style=fstr]{
[
\node{pred}{pred} &  `eat' \\
subj & \node{subj}{[ pred &  `Donatello']} \\
adj & \{[ pred &  `earlier']\}\\
tense & \node{past}{past}
]
}
\hfill
\begin{minipage}{\widthof{\emptybracks}}
\avm[pic,picname=sstr-1]{
\node{s-clause}{}\emptybracks\\
\node{s-arg1}{}\emptybracks\\
\node{s-arg2}{}\emptybracks
}
\end{minipage}
\begin{tikzpicture}[overlay,remember picture]
\node[fit=(astr-1-eat) (astr-1-patient)] (AS-Ex116-group-1) {};
\node[fit=(fstr-1-pred) (fstr-1-past) (fstr-1-subj)] (AS-Ex116-group-2) {};
\strucconnect{astr-1-agent}{fstr-1-subj.183}{0.3}{$\lambda$}{east}{195}
\strucconnect{AS-Ex116-group-1.20}{AS-Ex116-group-2.165}{0.5}{$\lambda$}{east}{west}
\strucconnect{AS-Ex116-group-2.20}{sstr-1-s-clause}{0.5}{$\sigma$}{east}{west}
\strucconnect{fstr-1-subj}{sstr-1-s-arg1}{0.5}{$\sigma$}{east}{west}
\end{tikzpicture}
\z
%
One might therefore be tempted to posit an unpronounced \OBJ attribute at
\fstruc{} corresponding to the Patient, but there is empirical evidence against
this \citep[71]{AsudGior12}. For example, this putative null pronoun cannot
antecede another, subsequent pronoun:

\ea
\begin{xlist}
  \ex[] {Donatello ate a pizza, but it turned out to be Raphael's.}%
  \ex[*] {Donatello ate, but it turned out to be Raphael's.}
\end{xlist}
\z
%
Given this, we are forced to propose a new function which projects directly from
\astruc{} to \sstruc{} (i.e. it is not simply the composition of $\sigma$ and
$\lambda$); \citet[70]{AsudGior12} call this the $\theta$ projection.
(\ref{ex:butt-et-al-architecture-augmented}) shows this new situation.

\vspace*{4\baselineskip}
\ea\label{ex:butt-et-al-architecture-augmented}
\avm[pic,picname=astr-2,style=fstr]{%
[
\node{rel}{rel} & \node{eat}{\normalfont\rmfamily eat}\\
agent & \emptybracks\node{agent}{}\\
patient & \emptybracks\node{theme}{}
]
}
\hfill
\avm[pic,picname=fstr-2,style=fstr]{
[
\node{pred}{pred} &  `eat' \\
subj & \node{subj}{[ pred &  `Donatello']} \\
adj & \{[ pred &  `earlier']\}\\
tense & past
]
}
\hfill
\begin{minipage}{\widthof{\emptybracks}}
\avm[pic,picname=sstr-2]{
\node{s-clause}{}\emptybracks\\
\node{s-arg1}{}\emptybracks\\
\node{s-arg2}{}\emptybracks
}
\end{minipage}
\begin{tikzpicture}[overlay,remember picture]
\node[fit=(astr-2-rel) (astr-2-theme) (astr-2-eat)] (astr-2-astr) {};
\node[fit=(fstr-2-pred) (fstr-2-subj)] (fstr-2-fstr) {};
\strucconnect{astr-2-agent}{fstr-2-subj.183}{0.3}{$\lambda$}{east}{195}
\strucconnect{astr-2-astr.20}{fstr-2-fstr}{0.5}{$\lambda$}{east}{west}
%
\strucconnect{fstr-2-fstr}{sstr-2-s-clause}{0.5}{$\sigma$}{east}{west} % <
\strucconnect{fstr-2-subj}{sstr-2-s-arg1}{0.5}{$\sigma$}{east}{west}
%
\strucconnect{astr-2-agent.east}{sstr-2-s-arg1.210}{0.5}{$\theta$}{-60}{240}
\strucconnect{astr-2-theme.east}{sstr-2-s-arg2.225}{0.5}{$\theta$}{-60}{240} % <
\strucconnect{astr-2-astr.20}{sstr-2-s-clause.135}{0.5}{$\theta$}{60}{120}
\end{tikzpicture}
\vspace*{4\baselineskip}
% \begin{tikzpicture}
% \node [draw,above=2em of fstr-2-fstr]{};
% \node [draw,below=2em of fstr-2-fstr]{};
% \end{tikzpicture}
\z
%
This move adds formal complexity to the grammar (a whole new projection
function) and also adds indeterminacy: when an element of \astruc{} \emph{is}
expressed at \fstruc{}, there are now two ways of reaching its \sstruc{} -- one
via $\sigma \circ \lambda$ and one via $\theta$ directly. Even if this solves
the problem of unexpressed arguments, it is a formally unhappy scenario to be
forced into.

\citegen{AsudGior12} solution is to do away with \astruc\ as a separate level of
representation, and to replace it with a new, connected version of \sstruc\ --
that is, rather than the \sstruc{}s for the arguments being separate from the
\sstruc{} for the clause (and from each other), they are instead embedded inside
it. This makes this new conception of \sstruc\ very similar to
\citegen{butt1997architecture} \astruc{}s. An example is shown in
(\ref{ex:new-architecture}):%
%

\ea\label{ex:new-architecture}
\avm[pic,picname=fstr-4,style=fstr]{%\textit{f-structure}\\
[
\node{pred}{pred} &  `eat' \\
subj & \node{subj}{[ pred &  `Donatello']} \\
adj & \{[ pred &  `earlier']\}\\
tense & \node{past}{past}
]
}
\hspace*{2em}
\avm[pic,picname=sstr-4,style=fstr]{%
[
rel &  eat  \\
\node{arg}{arg$_1$} & \node{arg1}{[rel &  Donatello]}\\
arg$_2$ & \node{arg2}{[rel &  var]}
]
}
\begin{tikzpicture}[overlay,remember picture]
\node [fit = (fstr-4-pred) (fstr-4-past) (fstr-4-subj)] (AS-Ex119-group1) {};
\node [fit = (sstr-4-arg) (sstr-4-arg1)] (AS-Ex119-group2) {};
\strucconnect{AS-Ex119-group1.-10}{AS-Ex119-group2}{0.5}{$\sigma$}{east}{west}
\strucconnect{fstr-4-subj.east}{sstr-4-arg1.175}{0.3}{$\sigma$}{-15}{160}
\end{tikzpicture}
\z
%

Ultimately, it is a fairly arbitrary choice whether we call this new connected
structure \sstruc\ or \astruc. \citet{AsudGior12} call it \sstruc{} since they
continue to use it as part of the linear logic component of Glue Semantics
meaning constructors, but it has a lot in common with
\citegen{butt1997architecture} \astruc{} as well, being internally
structured\slash connected and expressing the predicate-argument structure of
the clause. What is more, later developments have sought to imbue this new
structure with additional information about tense, aspect, and event structure
(see e.g. \citealt{Lowe2014,Lovestrand2018,Lovestrand2020,findlay2021}), thereby
incorporating some information which is also present in \citegen{Butt1995}
``elaborated'' \astruc{}s (on which see below). For consistency with other work,
however, we will continue to call these \sstruc{}s here.

The exact content of these \sstruc{}s is subject to ongoing research, but they
are assumed to at least include a \REL attribute identifying the semantic
relation expressed \citep[cf.][24]{asudeh2013constructions}, and potentially
several numbered \ARG attributes, e.g. \ARGnum{1}, \ARGnum{2}, for each of that
relation's arguments. \citet{AsudGior12} use \REL only for predicates, and leave
argument \sstruc{}s as ``empty'' AVMs, just like \citet{butt1997architecture}.
\citet[ch.~8.3]{Lovestrand2018} and \citet[135f.]{Findlay2020}, however,
generalise the presence of \REL to argument as well as predicate \sstruc{}s, and
\citet[144]{Findlay2020} proposes to use ``var'' as the \REL value for
unexpressed\slash suppressed arguments.

The numbered \ARG attributes are used instead of \citegen{butt1997architecture}
thematic role labels in part because \citet{AsudGior12} make use of a
neo-David\-so\-nian meaning language \citep{parsons1990events} such that thematic
role information is expressed directly in the semantics -- i.e. instead of
(\ref{ex:eat-meanings}a), the meaning of \textit{eat} is expressed by
(\ref{ex:eat-meanings}b) -- and so it would be redundant to also encode this
information in \sstruc{}.

\ea\label{ex:eat-meanings}
\ea
$\lambda x \lambda y \lambda e. \mathbf{eat}(e,x,y)$
\ex
$\lambda x \lambda y \lambda e. \mathbf{eat}(e) \land \mathbf{agent}(e,x) \land \mathbf{theme}(e,y)$
\z
\z
%
This has the additional benefit of relegating thematic roles to the meaning
language rather than making them part of the meta-language of the grammar
itself. There they can be treated as abbreviations for whatever sets of semantic
entailments we take them to encode (\textit{\`a la} \citealt{Dowty1991}), with
whatever level of granularity is required, leaving the grammar itself free of
the nebulous notion of thematic role.

\largerpage
The significance, or lack thereof, of the \ARG labels has been the subject of
disagreement, however. They were originally intended as arbitrary labels merely
to achieve distinctness at \sstruc{}, but \citet{findlay2017mapping} imbues them
with meaning, identifying them with the numbered arg positions of Kibort MT (see
Section~\ref{sec:argstr:morphosemantic-alternations}), as part of an implementation of
that theory within the new architecture. This view has been adopted by others
(e.g. \citealt{asudeh2014meaning,Lowe2015,Lovestrand2018,Lovestrand2020}), but
\citet{Findlay2020} argues for a return to the \textit{status quo ante}, where
these labels have no significance in and of themselves, and shows that the same
implementation of Kibort MT can be achieved while avoiding reifying the \sstruc\
attribute names.

The title of \citet{findlay2017mapping} is ``Mapping theory without argument
structure'', but this is in many respects a mischaracterisation of the research
programme inspired by \citegen{AsudGior12} architectural proposal. Rather than
doing away with argument structure, this work has served more as a
rationalisation of the LFG architecture: instead of having two levels, \astruc{}
and \sstruc{}, the latter of which is rather informationally impoverished, we
have a single level of representation which shares properties of both.%
%
\footnote{The observant reader may be entertaining an architectural concern at
  this point: earlier, we motivated the \citet{butt1997architecture}
  architecture by drawing on the facts of complex predicates: a complex
  \astruc{} can correspond to a simplex (monoclausal) \fstruc{}, and so we need
  the former to precede the latter in the projection architecture in order to
  retain the functional nature of the projection relations. However, in the new
  architecture, the connected \sstruc{} which represents predicate-argument
  structure comes after \fstruc{}, so we appear to be in trouble. Two solutions
  to this puzzle have been proposed. \citet{Lowe2015} gives the first analysis
  of complex predicates in this new framework, and argues that they should be
  given a flat \sstruc{} (in contrast to the articulated \astruc{}s usually
  assumed), representing their complexity in the meaning language instead. This
  avoids any problems arising from having a flat \fstruc{}, since it is no
  longer required to subsequently project a more articulated \sstruc.
  Alternatively, \citet{Lovestrand2020} proposes to give complex predicates
  articulated \fstruc{}s after all, which means a complex \sstruc{} is also
  possible without losing the functional nature of $\sigma$. There are empirical
  shortcomings with both of these approaches, but they fare no worse than
  existing, alternative approaches, and serve to illustrate how the apparent
  monoclausality of complex predicates does not force us to assume an
  articulated \astruc{} which precedes \fstruc{} in the projection
  architecture.}


As mentioned above, some researchers have imbued this new structure with
additional information about lexical semantics and event structure
\citep[e.g.][]{Lowe2014,Lovestrand2018}. But suggestions to add this kind of
information to \astruc\ are not new. \citet{Butt1995} develops what she calls an
\fm{elaborated \astruc} \citep[133]{Butt1995}, which includes much more
structure and much more semantic information than Classical LMT's minimalist
\astruc{}s. This elaborated \astruc{} is based on
\citegen{jackendoff1990semantic} \fm{Lexical Conceptual Structures} (LCSs), but
only includes the concepts relevant to linking and semantic case marking
\citep[143]{Butt1995}. An example of the elaborated \astruc{} for the Urdu main
verb \textit{de} `give' is shown in (\ref{ex:butt-elaborated-astruc}):

\eabox{\label{ex:butt-elaborated-astruc}
% \evnup{
\avm[id position=south-east, stretch=1.2]{%
[
\normalfont\rmfamily de `give'\\
\id{E}{[& $!\textnormal{CS}([\alpha], \textnormal{GO}_{\textit{Poss}}(\emptybracks, \textnormal{TO}\emptybracks))!$\\
&$!\textnormal{AFF}(\emptybracks^{\alpha},\ )!$\\
&$!\textnormal{ASP}(\_\; \_\; \_)!$
 ]}
]%
% }%
}
}

\noindent
The inner box is the actual \astruc{}, and contains three levels. The first two
are borrowed from Jackendoff's LCSs: the \fm{Thematic Tier} and the \fm{Action
  Tier}. The former, the Thematic Tier, describes the lexical meaning of the
verb in decompositional terms -- here that one entity \emph{causes} (CS)
\emph{possession} of another to \emph{go} (GO$_\textit{Poss}$) \emph{to} a third
entity (TO).
%
The latter, the Action Tier, describes the relationship between Actor, Patient,
and Beneficiary roles -- in other words those roles which usually receive
structural case. As \citet[137]{Butt1995} points out, it can also be thought of
as encoding an analogue of \citegen{Dowty1991} proto-roles. Here the argument
labelled $\alpha$, i.e. the ``giver'' (the one causing the transfer of
possession) is indicated to be \emph{affecting} (AFF) something else. The second
slot of the function AFF is left empty, indicating that there is no true Patient
or Beneficiary here (Butt treats the recipient as a simple Goal instead of a
Beneficiary). There are also subtypes of the AFF function which provide
information about volitionality or conscious choice.

The final tier is the \fm{Aspect Tier}. This is not borrowed from Jackendovian
LCSs, but is an innovation by Butt. It represents aspectual information:
specifically, whether a verb is positively or negatively specified for
inception, duration, and/or completion \citep[142]{Butt1995}. The function ASP
contains three slots, one for each of these properties, and each can be
specified positively, with a `1', negatively, with a `0', or left unspecified,
indicated by a `\_'. In (\ref{ex:butt-elaborated-astruc}), all three slots are
empty, showing that this verb is unspecified for this aspectual information.

Clearly, this conception of argument structure is far more complex than the
ordered lists used in Classical LMT, and more informationally rich than either
of the structures discussed already in this section.%
%
\footnote{Indeed, one reviewer suggests that the level of representation
  proposed by \citet{Butt1995} is not argument structure at all, but rather some
  kind of ``event structure'' or ``semantic structure''. To the extent that the
  additional information is necessary to handle argument structure phenomena
  like complex predicate formation, and given that these structures also do
  everything else we would want from an argument structure (see e.g.
  \citealt[ch.~6]{Butt1995} on mapping), it is hard to know what to make of this
  complaint. Perhaps a more minimal \astruc\ would in fact be sufficient, but if
  so that is a matter to be demonstrated empirically, rather than settled by
  definitional fiat.}
%
Butt argues that this complexity is motivated by its capacity to offer an
elegant account of complex predicates. For one thing, the elaborated \astruc{}s
expose more lexical semantic content to the grammar, enabling appropriately
fine-grained constraints to be placed on complex predicate formation (see e.g.
\citealt[147--155]{Butt1995} for examples). For another, they add articulation
and structure, and, as we saw in Section~\ref{sec:argstr:complex-preds}, the proper
treatment of complex predicates necessitates assuming a more articulated
\astruc\ than is standard in Classical LMT -- at least one capable of recursive
embedding.

On \citegen{Butt1995} approach, the light verbs which are used in complex
predicates have \astruc{}s which themselves have argument slots for \emph{other
  \astruc{}s}, labelled as \fm{transparent events} ($E_T$), since the light
verbs that host them can ``see into'' their internal structure. This visibility
allows different kinds of argument fusion to take place, whereby participants of
the embedded event are identified with participants of the event described by
the light verb (as discussed in Section~\ref{sec:argstr:complex-preds}). We omit the
full details here -- see \citet[ch.~5]{Butt1995} for more information. By way of
illustration, the \astruc{} for the Urdu permissive light verb \textit{de-}
`let' is given in (\ref{ex:permissive-astruc}) \citep[156]{Butt1995}:

\eabox{
\label{ex:permissive-astruc}
% %\evnup{
\avm[id position=south-east, stretch = 1.2]{%
[
\normalfont\rmfamily de- `let'\\
\id{E}{[& $!\textnormal{CS}([\alpha], \textnormal{GO}_{\textit{Poss}}(\emptycurlybracks_{E_T}, \textnormal{TO}\emptybracks))!$\\
&$!\textnormal{AFF}(\emptybracks^{\alpha},\ )!$\\
&$!\textnormal{ASP}(\_\; \_\; \_)!$
 ]}
]
}
}
%
This is very similar to the \astruc{} in (\ref{ex:butt-elaborated-astruc}), the
only difference being that the first argument of GO$_\textit{Poss}$ has been
replaced by a transparent event (indicated by the curly braces and subscript
$E_T$). The ``letting'' event expressed by this light verb is viewed
metaphorically as a transfer event, where the thing transferred is the permitted
event. This gives some explanation to the fact that both verbs share the same
form in Urdu, for example, and shows how the embedded verb contributes to the
overall interpretation of the complex predicate. It also allows for the
recursive construction of complex predicates which are embedded under more than
one light verb.%
%
\footnote{Other work on complex predicates and LMT, including Butt's own later
  work, has tended to eschew these more complex \astruc{}s in favour of the
  simpler, ordered list representations of Classical MT (e.g.
  \citealt{alsina1996the-role,Alsina1997,Butt2014}). But this leads to enormous
  difficulty in appropriately formalising the process of \fm{predicate fusion}:
  see \citet[sec.~2]{Lowe2015} for critical discussion.}
%

A more contemporary approach to expanding the coverage of \astruc, but without
assuming the \citet{AsudGior12} architecture, is that of
\citet[ch.~6]{schaetzle18}. She assumes a richly multidimensional version of
Kibort MT's \astruc, where each argument can be annotated with a variety of
non-standard semantic information, such as whether it is a \fm{Figure} or
\fm{Ground} \citep{talmy78}, and which kind of event participant it is in the
typology of \citegen{ramchand08} \fm{first-phase syntax}. This,
\citet[202]{schaetzle18} claims, enables a more ``semantically realistic''
account of mapping and of argument alternations, a goal shared by other recent
work -- see Section~\ref{sec:argstr:semantics}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mapping as co-description}\label{sec:argstr:nature-of-mapping}

The relationship between different levels of structure, such as \astruc\ and
\fstruc, has been approached in two different ways in LFG: \fm{co-description}
and \fm{description by analysis} \citep[267--270]{kaplan1995formal,DLM:LFG}. In
co-description, multiple levels of structure are described simultaneously -- for
example, LFG's annotated phrase-structure rules simultaneously describe both
\cstruc\ and \fstruc. This is the most commonly used approach in LFG. The
alternative, description by analysis, involves determining the description of
one structure by inspecting and analysing another. This was used in early LFG
proposals for semantic analysis \citep[e.g.][]{halvorsen83}.
\citet[344--345]{findlay2021} discusses various shortcomings of the description
by analysis approach: notably, it ignores the possibility of mismatches between
levels, and fails to meet the desideratum of constraint-based grammars laid down
by \citet[13]{pollard1994head-driven} that they be ``process neutral'':
description by analysis inevitably introduces directionality into parsing, which
co-description does not. Co-description therefore ``most directly captures the
spirit of the constraint-based approach to linguistic analysis''
\citep[344]{findlay2021}, which may explain why it has come to dominate in LFG
analyses -- indeed, while description by analysis was prominent in early
accounts of semantics in LFG, those approaches have since been replaced by Glue
Semantics (\citealp{dalrympleetal93,Dalrymple:Glue,asudeh22}), which employs
co-description.

Classical LMT, though, is very much in the spirit of description by analysis: GF
assignments at \fstruc\ are determined by inspecting \astruc, and by analysing
it using the Mapping Principle(s). This state of affairs meant that LFG work on
argument structure and mapping was out of sync with the theoretical mainstream,
where co-description was the norm. Once again, \citet[6]{butt1997architecture}
were the first to tackle this formal issue, treating mapping as co-description
of both a- and \fstruc.

For example, to say that a predicate's Agent argument is expressed as its \SUBJ
GF, we could include the following piece of functional description in its
lexical entry (where $*$ refers to the \cstruc{} node bearing the annotation,
and $\hat{*}$ to its mother node):

\ea\label{ex:simple-butt-etal-mapping}
$(\hat{*}_{\alpha}\ \textsc{agent})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \SUBJ)$
\z
\newpage\noindent
The expression $\hat*_{\alpha}$ refers to the lexical item's \astruc, via the
$\alpha$ projection from c- to \astruc, while the expression
$\hat*_{\alpha\lambda}$ refers to the lexical item's \fstruc\ (the equivalent of
the more familiar $\uparrow$). This constraint therefore picks out the \fstruc\
corresponding to the \astruc\ \textsc{agent}, and identifies it with the verb's
\fstruc\ \SUBJ.

But, of course, we generally don't want to associate an argument with only a
single GF. Instead, Classical LMT associates it with a feature which describes a
\emph{pair} of GFs. \citet[6]{butt1997architecture} make this disjunctive
meaning of the features explicit: instead of associating an argument with a
feature, a disjunction of mapping equations like
(\ref{ex:simple-butt-etal-mapping}) is given, as in
(\ref{ex:butt-etal-feature-decomposition-as-disjunction}) or
(\ref{ex:butt-etal-theme}):%
%
\ea\label{ex:butt-etal-feature-decomposition-as-disjunction}
\textit{\textsc{agent} links to $[-o]$:}\\
                 $(\hat{*}_{\alpha}\ \textsc{agent})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \SUBJ)\ \lor$\\
                 $(\hat{*}_{\alpha}\ \textsc{agent})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \OBLROLE{agent})$
\z

\ea\label{ex:butt-etal-theme}
\textit{\textsc{theme} links to $[-r] \lor [+o]$:}\\
                 $(\hat{*}_{\alpha}\ \textsc{theme})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \SUBJ)\ \lor$\\
                 $(\hat{*}_{\alpha}\ \textsc{theme})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \OBJ{})\ \lor$\\
                 $(\hat{*}_{\alpha}\ \textsc{theme})_{\lambda} = (\hat{*}_{\alpha\lambda}\ \OBJROLE{theme}) $
\z
%
\citet[6]{butt1997architecture} suggest that these intrinsic specifications can
be universal, like (\ref{ex:butt-etal-feature-decomposition-as-disjunction}) for
\textsc{agent}s and (\ref{ex:butt-etal-theme}) for \textsc{theme}s, or they can
be parameterised on a language-by-language basis, as is the case for other roles
like \textsc{location}, \textsc{goal}, or \textsc{instrument}.

%
Of course, these specifications alone do not determine the final mapping. In
fact, \citet[6]{butt1997architecture} propose an important theoretical break
from Classical LMT in this respect:

\begin{quote}
  Our approach departs most radically from the LMT literature in that we do not
  assume that \astruc\ roles are deterministically and uniquely linked to
  grammatical functions via a set of default principles. Instead, we propose a
  set of preference constraints which impose an ordering on the available
  linking possibilities; the most preferred possibility or possibilities are
  chosen.
\end{quote}
%
\largerpage[-1]
In essence, their approach rejects the mechanistic, rule-driven approach of
Classical LMT, and instead proposes that there is a hierarchy of GFs, and that
those mappings which realise more highly ranked GFs are preferred. The hierarchy
they propose is as follows:%
%
\footnote{\citet[7]{butt1997architecture} claim that the hierarchy in
  (\ref{ex:butt-etal-gf-hierarchy}) can be recast as a preference for
  negative-valued features in the classic $[\pm o/r]$ schema:

  \ea\label{ex:butt-etal-feature-rankings}%
  \ea $[-r] > [+r]$%
  \ex $[-o] > [+o]$%
  \z%
  \z
  %
  But the expressions in (\ref{ex:butt-etal-feature-rankings}), which is their
  (15), do not match the authors' prose description, which only applies
  (\ref{ex:butt-etal-feature-rankings}-b) within the $[-r]$ GFs. If we simply
  take (\ref{ex:butt-etal-feature-rankings}) as expressing two independent
  preference rankings, we get the Markedness Hierarchy of Classical LMT (see
  Section~\ref{sec:argstr:feature-decomposition}):

  \ea\label{ex:butt-etal-gf-hierarchy-total}%
  $\SUBJ > \OBJ, \OBLTHETA > \OBJTHETA$%
  \z
  %
  Alternatively, if we see (\ref{ex:butt-etal-feature-rankings}-a) as taking
  precedence over (\ref{ex:butt-etal-feature-rankings}-b), then we obtain
  another ranking, this time a total ordering:

  \ea $\SUBJ > \OBJ > \OBLTHETA > \OBJTHETA$ \z
%
  It is of course an empirical matter which of these rankings (if any) is
  correct.}
%

\ea\label{ex:butt-etal-gf-hierarchy}
$\SUBJ > \OBJ > \OBLTHETA, \OBJTHETA$
\z
%
That is, \SUBJ outranks \OBJ, which in turn outranks \OBLTHETA and \OBJTHETA,
which have the same rank as each other. This means, for each argument, that it
is preferable for it to be realised as a \SUBJ, or, failing that, as an \OBJ,
or, lastly, as either an \OBLTHETA or an \OBJTHETA. The argument will therefore
be linked to the highest GF on this hierarchy with which it is compatible, given
the disjunctive specifications provided in its intrinsic classification.%
%
\footnote{Just like Kibort MT's Mapping Principle (see
  Section~\ref{sec:argstr:morphosemantic-alternations}), this reverses the Classical
  LMT mapping principle where GFs \emph{lower} down the hierarchy are preferred.
  This means that \citegen{butt1997architecture} proposal shares the weakness of
  Kibort MT that it makes the wrong prediction about the passives of
  ditransitives -- see Section~\ref{sec:argstr:arg-alternations-in-lmt}.}
%
This gives us a much more dynamic system than in Classical LMT: there are no
explicit Mapping Principles, and arguments simply compete for the highest
available GFs. In a nod to Mapping Principle (a-i) of Classical LMT (see
Section~\ref{sec:argstr:lmt-initial}), \citet[6]{butt1997architecture} do include a
preference for the \SUBJ to be linked to the highest available argument on the
thematic hierarchy, but crucially this is just a preference, and so is not
inviolable.

The final mapping chosen is the one deemed ``optimal'' in terms of realising the
highest number of the most highly ranked GFs, and in terms of satisfying any
other preference constraints, such as the subject preference just mentioned (as
well as not violating Function-Argument Biuniqueness or the Subject Condition).
\citet[7]{butt1997architecture} use a numerical system to express the relative
weightings of different GFs and of other constraints, but this is not a crucial
component of the theory, and any appropriate means of ranking different
solutions in terms of a set of preferences could be used -- for example, the
authors speculate (p.~7) that the proposal could be reformulated in terms of
Optimality Theory (\citealp{PrinceSmolensky1993,PrinceSmolensky2004}, \textit{et
  seq.}).

By way of illustration, consider a simple transitive like \textit{kick} again.
For every argument, the most preferred GF is \SUBJ. But is each compatible with
\SUBJ? According to the disjunctions in
(\ref{ex:butt-etal-feature-decomposition-as-disjunction}) and
(\ref{ex:butt-etal-theme}), assuming that the intrinsic classification for Theme
also applies to Patients, \SUBJ is a possible realisation of both arguments. But
we cannot map both to \SUBJ, or we fall foul of Function-Argument Biuniqueness,
so we must decide which one to map to \SUBJ, and which to map to the next most
highly ranked compatible GF. Since, following the thematic hierarchy, the Agent
argument of \textit{kick} outranks its Patient argument, the subject preference
will be satisfied if we map the Agent to \SUBJ but not if we map the Patient to
\SUBJ, so the former mapping is preferred; the next highest GF compatible with
the Patient intrinsic specification is \OBJ, and so we end up with the correct
outcome whereby the Agent is linked to \SUBJ and the Patient to \OBJ.

The theoretically most interesting consequence of the
\citet{butt1997architecture} approach to mapping is that certain constructions
may have more than one optimal linking. \citet[8ff.]{butt1997architecture} argue
that this in fact characterises alternations which are motivated by
semantic\slash pragmatic constraints (such as the dative shift) and not by
morphosyntactic ones (such as the passive).%
%
\footnote{However, their distinction does not seem to perfectly match that
  between meaning-preserving (morphosyntactic) and meaning-altering
  (morphosemantic) alternations, since they consider the locative inversion to
  be grouped with the dative shift (as being explained by the presence of more
  than one optimal linking) and distinct from the passive, when the locative
  inversion is no more meaning altering than the passive (neither alternation
  affects truth-conditional semantics, but only alters the information
  structural prominence of its arguments).}
%
This offers a more natural account of the dative shift alternation than the
Classical LMT analysis, which requires two different initial assignments of
features to the arguments. In the \citet{butt1997architecture} framework, both
realisations of the dative shift alternation in English are made available
automatically, since they have equivalent preference rankings:

\begin{exe}
\ex \gll [Garak] gave {[the datarod]} {[to Sisko]}.\\
\SUBJ{} {} \OBJ{} \OBLROLE{goal}\\

\ex \gll [Garak] gave [Sisko] {[the datarod]}.\\
\SUBJ{} {} \OBJ{} \OBJROLE{theme}\\
\end{exe}
%
Both involve a \SUBJ (linked to the highest argument) and an \OBJ, and since
\OBJTHETA and \OBLTHETA are equally ranked, the different realisations of the
third argument make no odds when it comes to the relative weightings of the two
mappings. Therefore both mappings are made available by the grammar, and the
choice between them must be determined by other factors, such as lexical
preference (the shifted variant is impossible with verbs of Latinate origin, for
example) or semantic\slash pragmatic considerations (see \citealt{Bresnan2007}
and \citealt{Bresnan07predicting} for usage-based\slash probabilistic accounts
of the alternation, and \citealt[ch.~6]{goldberg1995constructions} on the
special meanings associated with the double object construction in English).


Work which assumes the \citet{AsudGior12} architecture also makes use of
co-description to express mapping possibilities, although here the
directionality is changed: we are mapping from \fstruc\ to \sstruc, rather than
from \astruc\ to \fstruc. The equivalent of (\ref{ex:simple-butt-etal-mapping}),
assuming \ARGnum{1} corresponds to the Agent (see Section~\ref{sec:argstr:semantics}),
is (\ref{ex:das-equivalent}):

\ea\label{ex:das-equivalent} (\UP \SUBJ)$_\sigma$ = (\UPS \ARGnum{1}) \z
%
As in \citet{butt1997architecture}, feature decomposition is replaced by
explicit disjunctions over GFs. \citet[299]{findlay2017mapping} uses
abbreviations to describe the (supposedly) natural classes captured by the
traditional features:

\ea\label{ex:feature-disjunctions}
\begin{tabular}[t]{clcl}
  a. & \textsc{minuso} & $\equiv$ &{$\{\SUBJ \vert \OBLTHETA\}$}\\
  b. & \textsc{pluso} & $\equiv$ & $\{\OBJ \vert \OBJTHETA \}$\\
  c. & \textsc{minusr} & $\equiv$& {$\{\SUBJ \vert \OBJ\}$}\\
  d. & \textsc{plusr}& $\equiv$ & {$\{\OBLTHETA \vert \OBJTHETA\}$}
\end{tabular}
\z
%
This gives us (\ref{ex:das-equivalent-disjunction}) as the equivalent of
(\ref{ex:butt-etal-feature-decomposition-as-disjunction}):

\ea\label{ex:das-equivalent-disjunction}%
(\UP \textsc{minuso})$_\sigma$ = (\UPS \ARGnum{1})%
\z

In fact, since arguments may not be realised by any GF -- for example, the Agent
argument of a short passive -- we also need a description which says that the
argument in question does not correspond to any GF at \fstruc. We achieve this
by stating that the inverse of the $\sigma$ mapping from f- to \sstruc\ is empty
when applied to that argument, as in (\ref{ex:empty-inverse}):

\ea\label{ex:empty-inverse}%
(\UPS \ARGnum{1})$_{\sigma^{-1}}$ = $\varnothing$%
\z
%
This says that the \sstruc{} \ARGnum{1} has no \fstruc\ correspondent, i.e. that
this argument is not realised syntactically.


\citet[319, 321]{findlay2017mapping} proposes to use templates to abbreviate
these mapping equations and make them more readable:%
%
\footnote{On templates, see
  \citet{dalrymple2004linguistic,xledoc,asudeh2013constructions} and
  \textcitetv[\ref{sec:CoreConcepts:templates}]{chapters/CoreConcepts}.}
%

\ea\label{ex:map-template}
\template{Map(D, A)}{%
(\UP \textsc{D})$_\sigma$ = (\UPS \textsc{A})
}
\ex\label{ex:nomap-template}
\template{NoMap(A)}{%
(\UPS \textsc{A})$_{\sigma^{-1}}$ = $\varnothing$
}
\z
%
The first of these, (\ref{ex:map-template}), says that the GF or disjunction of
GFs D is mapped to the \sstruc{} argument A, while (\ref{ex:nomap-template})
says that the \sstruc{} argument A has no GF correspondent at \fstruc{}.%
%
\footnote{One problem with the \textsc{NoMap} template is that in the event an
  argument is not expressed syntactically, nothing will ensure its presence at
  \sstruc{}. \citet[135--136]{Findlay2020} argues therefore that existential
  constraints must accompany the introduction of each argument.}
%
These templates can then be combined, so that e.g. the correct expression to
capture the mapping possibilities of an Agent assigned to \ARGnum{1} is the
following:

\ea\label{ex:mapping-full}
$\big\{\textsc{@Map(minuso, \ARGnum{1})}\, \vert\, \textsc{@NoMap(\ARGnum{1})}\big\}$
\z
%
That is, either this argument is mapped to one of the two \textsc{minuso} GFs
(\SUBJ or \OBLTHETA), or it is not expressed syntactically at all.

Using disjunctions over GFs like \textsc{minuso} or \textsc{plusr} instead of
assuming features like $[-o]$ and $[+r]$ sidesteps any formal issues arising
from seeing GFs as decomposable into features (as discussed in
Section~\ref{sec:argstr:feature-decomposition}), and simply represents the most
significant empirical claim of the feature-based approach -- that GFs can be
grouped into natural classes (whether the $[\pm o/r]$ classification is the
correct way of grouping them is orthogonal). It has been objected that this use
of disjunctions makes the approach somehow more arbitrary or less well motivated
than earlier incarnations of LMT, since we could just as easily have written a
different set of disjunctions in (\ref{ex:feature-disjunctions}). Such an
objection is misplaced for two important reasons. Firstly, it purports to
contrast the arbitrariness of the disjunctive approach with the theoretical
motivation of the feature-decomposition approach. But this is only true to the
extent that the features used in the latter have independent motivations. While
a case could be made for $[\pm r]$ on these grounds (one could imagine an
independent criterion for determining semantic restrictedness), as we mentioned
in Section~\ref{sec:argstr:feature-decomposition}, this seems not to be the case for
$[\pm o]$, which has no content other than identifying the two object functions
\OBJ and \OBJTHETA, and whose definition is therefore circular. Given this
situation, we take the use of the explicitly ``arbitrary'' mechanism of
disjunction to in fact be an advantage over the classical approach, since it
wears its arbitrariness on its sleeve rather than concealing it behind a veneer
of theoretical motivation.

Secondly, and much more significantly, such an objection misses the crucial
distinction between formalism and theory. The formalism \emph{itself} need not
be expected to say anything about what natural groupings of GFs occur in the
world's languages. Rather, the formalism gives us tools for making explicit
claims about such things -- and it is those claims which constitute the theory.
As \citet[9]{poll:97:nature} puts it, ``it is the theory that imposes the
constraints, not the language in which the theory is expressed''. So, although
we could've written different disjunctions in (\ref{ex:feature-disjunctions}),
it is precisely in writing one set of expressions rather than another that we
make a theoretical claim. This claim may turn out to be true or false, but if it
is false, we would prefer to be able to use the same familiar tools to express a
different, revised hypothesis, rather than have to throw away our tools entirely
because they have been over-engineered to fit one particular view of reality.
Once again, therefore, we see this property as being an advantage of the
disjunctive approach. As an example, consider the objection by \citet[29,
fn.~9]{alsina1996the-role}, noted in Section~\ref{sec:argstr:feature-decomposition},
that the traditional $[\pm o/r]$ features cannot be used to describe the natural
class of terms, or direct GFs, i.e. \SUBJ, \OBJ, and \OBJTHETA. He instead
proposes a different classification using the features
$[\pm \textnormal{subj/obl}]$, where $[-\textnormal{obl}]$ describes the terms
\citep[27--30]{alsina1996the-role}. In the traditional view, this approach and
the Classical LMT approach are simply incommensurable: they represent two
different formalisms which contain different primitive elements. But in the view
we are considering, both can be expresed in the \emph{same} terms -- compare
(\ref{ex:feature-disjunctions}) and (\ref{ex:alsina-templates}) -- thereby
highlighting their status as competing theoretical claims rather than totally
distinct formal approaches.

\ea\label{ex:alsina-templates}
\begin{tabular}[t]{clcl}
  a. & \textsc{minusSubj} & $\equiv$ & {$\{\OBJ \vert \OBJTHETA \vert \OBLTHETA\}$}\\
  b. & \textsc{plusSubj} & $\equiv$ & {\SUBJ}\\
  c. & \textsc{minusObl} & $\equiv$ & {$\{\SUBJ \vert \OBJ \vert \OBJTHETA\}$}\\
  d. & \textsc{plusObl} & $\equiv$ & {\OBLTHETA}
\end{tabular}
\z
%
It is an empirical matter which of these analyses is correct, and we should not
generally expect the formalism to adjudicate on empirical matters. Rather, the
theory which we develop in using that formalism is what we expect to align with
the facts.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Connection to semantics}\label{sec:argstr:semantics}

While the most influential research in Classical LMT was being conducted, there
was no canonical theory of the syntax-semantics interface in LFG to appeal to.
With the acceptance of \fm{Glue Semantics} (Glue) into the LFG mainstream around
the turn of the millennium, this changed.%
%
\footnote{Although Glue first appeared in the early '90s
  \citep{dalrympleetal93}, it was still not well established in the LFG
  community by the time much of the the work discussed in the earlier sections
  of this chapter was carried out. The first major collection of Glue work
  connected to LFG was \citet{Dalrymple:Glue}, and the theory later appeared in
  \citegen{dalrymple01} handbook-style presentation of LFG, as well as the
  latest reference guide to LFG, \citet[ch,~8.5]{DLM:LFG}. We cannot include an
  introduction to Glue Semantics in this chapter for reasons of space, but see
  the references just cited, along with \citet{asudeh22} and
  \textcitetv{chapters/Glue} for further information.}
%
One of the most important goals of recent work on mapping theory has therefore
been to integrate the theory into a Glue-based analysis of the syntax-semantics
interface. In particular, this strand of research assumes that Glue's concept of
\fm{resource sensitivity} \citep[ch.~5]{Asudeh12} subsumes the traditional LFG
principles of Completeness and Coherence, so that \PRED features at \fstruc{} no
longer contain an argument list. That is, instead of
(\ref{ex:diff-semantic-forms}a), we have (\ref{ex:diff-semantic-forms}b):%
%
\footnote{The idea of using linear logic's resource sensitivity to account for
  Completeness and Coherence goes back to the very first Glue paper
  \citep{dalrympleetal93}, and was noted again by
  \citet{dalrymple-etal1999intro}, \citet{kuhn2001}, and
  \citet[112ff.]{Asudeh12}, though it didn't find its way into more mainstream
  LFG work until the research programme initiated by \citet{AsudGior12}.

  One oft-noted (potential) problem with viewing Completeness and Coherence as
  reducible to semantic resource sensitivity is expletive arguments, i.e.
  syntactic arguments which do not correspond to semantic ones. Since, by
  hypothesis, they make no semantic contribution, they will not be required by
  constraints of semantic resource sensitivity, even though they \emph{are}
  required for grammaticality. As \citet[113]{Asudeh12} points out, however,
  this is far from an insurmountable problem, and there are a number of
  potential solutions (including rejecting the idea that expletive arguments are
  semantically empty in the first place -- see \citealt{bolinger1977}).}
%

\ea\label{ex:diff-semantic-forms}
\ea \avm[style=fstr]{[pred &  `eat\arglist{subj, obj}']}
\ex \avm[style=fstr]{[pred &  `eat']}
\z
\z
%
This creates greater flexibility when it comes to argument realisation, since
one and the same \PRED value can correspond to different syntactic realisations
of its arguments. In the previous conception, each argument array required a
separate \PRED value (and therefore a separate lexical entry), since \PRED
values cannot be manipulated in the syntax (cf. the principle of Direct
Syntactic Encoding introduced in Section~\ref{sec:argstr:lexical-rules}, and discussed
further in \citealp{kaplanbresnan82}, \citealp[sec.~5.2]{BresnanEtAl2016}, and
\citealp[329]{DLM:LFG}).%

A typical lexical entry in this strand of work is given in
(\ref{ex:kick-lexical-entry}):

\ea\label{ex:kick-lexical-entry}
\catlexentry{kick}{V}{%
(\UP \PRED) = \normalfont\rmfamily `kick'\\
(\UPS \REL) = \normalfont\rmfamily kick\\
\\
% \fbox{\pbox{\textwidth}{%
$\big\{\textsc{@Map(minuso, \ARGnum{1})}\, \vert\, \textsc{@NoMap(\ARGnum{1})}\big\}$\\[0.5ex]
$\big\{\textsc{@Map(minusr, \ARGnum{2})}\, \vert\, \textsc{@NoMap(\ARGnum{2})}\big\}$
% }}
\\
\\
$\lambda x \lambda y \lambda e.\mathbf{kick}(e) \land \mathbf{agent}(e,x) \land \mathbf{patient}(e,y):$\\
$(\UPS\ \ARGnum{1}) \multimap (\UPS\ \ARGnum{2}) \multimap (\UPS\ \textsc{event}) \multimap \UPS$
}
\z
%
\largerpage
The first two lines provide the \PRED value along with a value for \REL at \sstruc{}.%
%
\footnote{The current status of \PRED and \REL in LFG is not settled: many if
  not all of the important functions of \PRED have been taken over by Glue
  Semantics \citep{andrews2008}, and \REL really has no substantive role in the
  theory (\citealt[169ff.]{Lovestrand2018}; although see \citealt{Lowe2014}).
  They also seem to both express the same information in
  (\ref{ex:kick-lexical-entry}), which adds a degree of redundancy to the
  grammar. Nevertheless, they at least serve to help distinguish different f-
  and \sstruc{}s, as well as making the representations more readable.}
%
The next two lines provide the mapping information, using the technique
explained in the previous section: either the arguments map to one of a pair of
GFs, or they are not realised syntactically. This corresponds to
argument-function mapping in Kibort MT (see
Section~\ref{sec:argstr:morphosemantic-alternations}). The crucial advantage of
incorporating a theory of the syntax-semantics interface is that we can also
express the equivalent of Kibort MT's argument-participant mapping, via the
meaning constructor in the final line. Here the variable $x$ is identified as
the Agent of the kicking event, and connected via the linear logic term to
\ARGnum{1} at \sstruc{}; similarly, $y$ is identified as the Patient, and
connected to \ARGnum{2}. That is, the link between GFs and semantic
participants, a key part of any mapping theory, is mediated by the intervening
level of \sstruc, here playing the same role as Kibort MT's lexical valency
frame. And just like in Kibort MT, this setup allows for the realignment of
participants to argument positions -- see \citet[328--332]{findlay2017mapping}
for an example of this with the English benefactive.

By bringing together information about mapping and about semantics, which are
just the same kind of object in this approach, \textit{viz.} pieces of
functional description, it becomes far easier to express semantic constraints
on, and semantic consequences of, argument alternations and other argument
structure operations (cf. also the discussion of \citegenalt{Butt1995} enhanced
\astruc{}s above). \citet[32--39]{asudeh:unrealized} shows the potential of this
approach in his analysis of the English ``non-agentive dynamic intransitive'',
and contrasts it with what he calls the ``low resolution'' of Classical LMT,
which only has access to very spartan semantic information (usually just the
thematic roles of arguments).

% Such an enriched representation might also offer a means of filling in the
% details of Kibort MT's deliberately ``low resolution'' treatment of semantic
% participants, and opens the way to a more explanatory theory of
% argument-participant mapping more generally.

One promising area of research made possible by this ``joined up'' approach to
mapping is the idea of incrementally bundling up semantic and mapping
information into more and more complex valency templates \citep[as employed in
e.g. ][]{AsudGior12,asudeh2014meaning,Findlay2020}, which, coupled with the
notion of an inclusion hierarchy between templates \citep[see
especially][17--20]{asudeh2013constructions}, could lead to a mapping theory
based purely on a richly structured and hierarchical lexicon, along the lines of
\citet{davisKoenig2000}. This potential has yet to be fully explored, though
\citet{przep2017hierarchical} has pointed the way.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:argstr:conclusion}

New approaches to argument structure and mapping theory phenomena were at the
heart of what gave rise to LFG as a separate approach to linguistic theory in
the first place: \citeauthor{bresnan:polyadicity}'s
(\citeyear{bresnan:polyadicity}, \citeyear{bresnan1982the-passive}) observations
about the lexical character of argument alternations and the benefits afforded
by separating out lexical predicate-argument structures from surface syntactic
structures were what laid the foundations for LFG's lexicalist, modular view of
the grammar. The advent of Lexical Mapping Theory (LMT) helped to constrain the
theory of argument alternations, and also offered new explanatory tools which
proved successful in characterising a number of linguistic phenomena across a
fairly typologically diverse range of languages. Recent developments in both
theory and formalism show that the field is ripe for a renaissance, and that
while great strides have been made, many important questions still remain
unanswered. This chapter has attempted to give a broad and expository overview
of the status quo, along with a little of how we got here, with the hope that by
drawing together different theoretical perspectives we can both encourage
dialogue among experienced researchers, and bring new scholars up to speed, so
that both can be in the best position to contribute to a field which remains
full of untapped potential.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{Further reading}\label{furtherreading}
% Constraints of space and time have precluded discussion of many interesting topics in this very rich area of research. Here we attempt to partially make up for these omissions by directing the reader to the relevant literature.

% One important omission is the topic of argument structure and mapping within the
% nominal, rather than verbal, domain. \textcitetv{chapters/NounPhrases} provide a
% useful summary of some of the issues. The classic text on this in LFG is
% \citet{Rappaport83}, which is also the source of the idea, now quite
% influential, that, where nominals are derived from verbs, they inherit the
% verb's argument structure, but that mapping itself is rather more constrained
% within the noun phrase in comparison to the verbal domain
% \citep{Laczko00,kelling2003,ChisaPayn01,ChisaPayn03,Laczko01,Laczko07}. The
% possibility that nominals do not have argument structure in common with verbs,
% or indeed no argument structure at all, has also been raised \citep{ramchand97,
%   Lowe17, taylorphd2023}, which gives a rather different account of the contrasts between clauses and noun phrases when it comes to argument realisation.

% There has been work on a range of languages with respect to nominal argument
% structures and their mapping possibilities within LFG: see
% \citet{kelling2003} on French,
% \citet{Markantonatou1995} on Modern Greek,
% \citet{Falk01actnom} on Modern Hebrew,
% \citet{sulger2012} on Hindi-Urdu,
% \citet{Laczko00,Laczko01,Laczko2004,Laczko10} on Hungarian,
% \citet{Saiki1987} on Japanese,
% and
% \citet{taylorphd2023} on Old English.
% % \citet{ramchand97} on Scottish Gaelic, % Not LMT
% See also \citet{Lowe17} for an alternative perspective within LFG, drawing on
% evidence from Sanskrit and other early Indo-Aryan languages.

% Another significant area we have not been able to address is that of case
% marking. Within LFG, the complex inter-relationship between arguments,
% grammatical functions, and case marking has been addressed by
% \citet{ZMT85:Case,allen1995case,Butt2006,schaetzle18}. For an implementation in
% XLE which handles case phenomena in Urdu, taking into account argument mapping,
% see \citet{buttking01nonnom}, and for an XLE implementation of a case-based
% analysis of French enclitics, see \citet{alencarschwarze2021}.

% At the turn of the millennium there was interest in connecting LFG and
% Optimality Theory; this trend was felt in work on mapping theory as well. For
% some examples, see \citeauthor{morimoto1999} (\citeyear{morimoto1999},
% \citeyear{Morimoto2000}) and \citet{Asudeh01}.

% Mapping theory has also been investigated in relation to language acquisition:
% see \citet{pienemann2005extending,kawaguchi2007, kawaguchi2009acquiring,
%   dibiasetal2015, iwasaki2018describing,ranliefl}.

\section*{Acknowledgements}
We would like to thank in the strongest possible terms the four anonymous
reviewers whose extremely detailed comments have vastly improved the quality of
this chapter. Jamie Findlay also gratefully acknowledges the financial support
of Research Council of Norway grant number 300495, ``Universal Natural Language
Understanding''.


\printbibliography[heading=subbibliography,notkeyword=this]

\end{document}
